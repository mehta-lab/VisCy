# Data Organization for Virtual Staining

> This advisory only applies to data management on Biohub's compute infrastructure.
> It is not normative for external users.

Here we document the conventions for storing data, metadata, configs,
and models during the development of the virtual staining pipeline.

## Data flow in the pipeline

TODO: Following diagram captures the planned flow of data and metadata through the new version of the pipeline.

### Preprocessing

Parameters are provided via the CLI, and stored in the attributes of
the OME-Zarr datasets using [iohub](https://github.com/czbiohub/iohub).
The metadata is in json format that is practical to edit by hand.

### Training

We use the PyTorch Lightning framework for training,
which provides [good defaults](https://pytorch-lightning.readthedocs.io/en/1.6.5/common/lightning_cli.html)
for CLI and training configs,
and organized TensorBoard [logs](https://lightning.ai/docs/pytorch/stable/extensions/logging.html).

### Inference

The inference module does not depend on lightning, but just on PyTorch.
Parameters are provided with CLI and stored with the OME-Zarr datasets,
similar to preprocessing.

> This can be further incorporated into the lightning pipeline

### Evaluation

Evaluating the models requires human proof-reading of ground truth.
Currently computing the evaluation metrics does not depend on PyTorch.

> This can be further incorporated into the lightning pipeline

### Deployment

For run-time deployment, we export the model to the ONNX format.

## Data hierarchy

Data generated by the pipeline is stored on the file system following this schema:

```yaml
# project root directory
virtual_staining:
    # registerd, deconvolved, preprocessed OME-Zarr stores
    datasets:
        train:
            yyyymmdd_dataname0.zarr
            yyyymmdd_dataname1.zarr
            ...
        test:
            yyyymmdd_dataname0.zarr
            yyyymmdd_dataname1.zarr
            ...
        # FOVs with human-proof-read ground truth segmentation masks
        ground_truth:
            yyyymmdd_dataname0_gt:
                fovs.zarr
                <frame0>.tif
                <frame0>_mask.png
                <frame1>.tif
                <frame1>_mask.png
                ...
            yyyymmdd_dataname1_gt:
                ...
            ...
    # computational experiments
    models:
        experiment0:
            # working training configs (may not specify default fields)
            training_config0.yaml
            training_config1.yaml
            ...
            lightning_logs:
                # output of one run
                yyyymmdd-hhmmss:
                    # model weights
                    checkpoints:
                        epoch0.ckpt
                        epoch1.ckpt
                        ...
                    # autosaved full config
                    config.yaml
                yyyymmdd-hhmmss:
                    ...
            # evaluation of select models
            evaluation: 
                # configs for evaluation: checkpoint path, test data path, ground turth path, and choice of metrics.
                evaluation_01.yaml
                evaluation_02.yaml
                ...
                # inference output on test dataset, may include copies of input and ground truth to facilitate visualization of model performance. 
                prediction_01.zarr
                prediction_02.zarr
                ...
                # evaluation metrics
                metrics_01.csv
                metrics_02.csv
                ...
                # (optional) tensorboard logs generated to visualize distribution of metrics or specific samples of input, prediction, ground truth.
                evaluation_logs: 
            # (optional) exported models for deployment
            deployment:
                <task>_<input_shape>.onnx
                README
        experiment1:
            ...
        ...
```
