# %% Imports
from pathlib import Path
from tempfile import TemporaryDirectory
import pandas as pd
from lightning.pytorch import Trainer
from lightning.pytorch.loggers import CSVLogger
from viscy.representation.embedding_writer import read_embedding_dataset
from viscy.representation.evaluation import load_annotation
from viscy.representation.lca import train_and_test_linear_classifier
from sklearn.metrics import classification_report
import numpy as np
import matplotlib.pyplot as plt
from pytorch_lightning import seed_everything

# %% Set random seed for reproducibility
seed_everything(42, workers=True)

# %% Paths for embedding and annotation data
path_embedding = Path(
   "/hpc/projects/intracellular_dashboard/viral-sensor/infection_classification/models/time_sampling_strategies/time_interval/predict/feb_test_time_interval_1_epoch_178.zarr"
)
path_annotations_infection = Path(
   "/hpc/projects/intracellular_dashboard/viral-sensor/2024_02_04_A549_DENV_ZIKV_timelapse/8-train-test-split/supervised_inf_pred/extracted_inf_state.csv"
)


# %% Load embedding and infection data
dataset = read_embedding_dataset(path_embedding)
features = dataset["features"].to_numpy()


infection = load_annotation(
   dataset,
   path_annotations_infection,
   "infection_state",
   {0.0: "background", 1.0: "uninfected", 2.0: "infected"},
)


# Prepare DataFrame with embeddings, ids, and FOV names
embedding_df = pd.DataFrame(features, columns=[f"feature_{i+1}" for i in range(features.shape[1])])
embedding_df["id"] = dataset["id"].values
embedding_df["fov_name"] = dataset["fov_name"].values
embedding_df["track_id"] = dataset["track_id"].values


# Merge embedding data with infection labels
merged_df = pd.merge(embedding_df, infection.reset_index(), on=["fov_name", "id"])


# Convert features and labels to NumPy arrays
X = merged_df.drop(columns=["id", "fov_name", "track_id", "infection_state"]).values  # Embeddings as features
y = merged_df["infection_state"].values  # Infection state labels
label_mapping = {"background": 0, "uninfected": 1, "infected": 2}
y = np.array([label_mapping[label] for label in y])


# %% Temporary directory for logging
temp_dir = TemporaryDirectory()
log_path = Path(temp_dir.name)
# %%


# Train the classifier using the embeddings and infection labels, with SMOTE applied to the training data
train_and_test_linear_classifier(
   embeddings=np.array(X),  # Full dataset
   labels=np.array(y),  # Full labels dataset
   num_classes=3,  # 3 classes: background, uninfected, infected
   trainer=Trainer(max_epochs=80, logger=CSVLogger(log_path), log_every_n_steps=1),
   split_ratio=(0.4, 0.2, 0.4),  # Automatically split 40% train, 20% val, 40% test
   batch_size=2**14,
   lr=0.001,
   use_smote=True,
   save_predictions=True,
   csv_path=Path("/hpc/mydata/alishba.imran/VisCy/applications/contrastive_phenotyping/evaluation/test_predicted_labels.csv"),
   merged_df=merged_df
)


# %% Plot Loss Curves for Training and Validation
# Read the logged losses from CSV generated by PyTorch Lightning
losses = pd.read_csv(
   log_path / "lightning_logs" / "version_0" / "metrics.csv", index_col="epoch"
)


# Merge the training and validation losses for comparison
losses = pd.merge(
   losses["loss/train"].dropna(), losses["loss/val"].dropna(), on="epoch"
)


# Plot the loss curves
plt.figure(figsize=(10, 6))
losses.plot()
plt.title("Training and Validation Loss Over Epochs")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()


# %% Clean up temporary directory
temp_dir.cleanup()
