seed_everything: 42
trainer:
  accelerator: gpu
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 32-true
  callbacks:
    - class_path: viscy.representation.embedding_writer.EmbeddingWriter
      init_args:
        # FIXME: Change this to the desired output path
        output_path: dynaclr/predict/time_interval_1.zarr
  inference_mode: true
model:
  encoder:
    class_path: viscy.representation.contrastive.ContrastiveEncoder
    init_args:
      backbone: convnext_tiny
      in_channels: 1
      in_stack_depth: 1
      stem_kernel_size: [1, 4, 4]
      stem_stride: [1, 4, 4]
      embedding_dim: 768
      projection_dim: 32
      drop_path_rate: 0.0
  example_input_array_shape: [1, 1, 1, 128, 128]
data:
  # FIXME: Change the path to downloaded data
  data_path: ../../Hela_CTC.zarr
  # NOTE: same as above for this example
  tracks_path: ../../Hela_CTC.zarr
  source_channel:
    - DIC
  z_range: [0, 1]
  # NOTE: reduce this if running out of memory
  batch_size: 16
  num_workers: 4
  initial_yx_patch_size: [128, 128]
  final_yx_patch_size: [128, 128]
  time_interval: 1
  normalizations:
    - class_path: viscy.transforms.NormalizeSampled
      init_args:
        keys: [DIC]
        level: fov_statistics
        subtrahend: mean
        divisor: std
return_predictions: false
# FIXME: Change this to the trained checkpoint path
ckpt_path: dynaclr/lightning_logs/time_interval_1/checkpoints/last.ckpt
