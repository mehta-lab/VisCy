{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd181c63",
   "metadata": {},
   "source": [
    "Image translation (Virtual Staining)\n",
    "\n",
    "Written by Eduardo Hirata-Miyasaki, Ziwen Liu, and Shalin Mehta, CZ Biohub San Francisco.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this exercise, we will:\n",
    "- Train a phase to fluorescence model to predict fluorescence images of\n",
    "nuclei and plasma membrane markers from quantitative phase images of cells\n",
    "- Train a fluorescence to phase model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f2966c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "Set your python kernel to <span style=\"color:black;\">img2img</span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad928d",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: Log training data to tensorboard, start training a model.\n",
    "---------\n",
    "Learning goals:\n",
    "\n",
    "- Load the OME-zarr dataset and examine the channels (A549).\n",
    "- Configure and understand the data loader.\n",
    "- Log some patches to tensorboard.\n",
    "- Train a 2D UNeXt2 model for virtual staining of nuclei and membrane from phase.\n",
    "- Evaluate the model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43abc269",
   "metadata": {
    "title": "Imports"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchview\n",
    "import torchvision\n",
    "from iohub import open_ome_zarr\n",
    "from iohub.reader import print_info\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from numpy.typing import ArrayLike\n",
    "from skimage import metrics  # for metrics.\n",
    "\n",
    "# pytorch lightning wrapper for Tensorboard.\n",
    "from torch.utils.tensorboard import SummaryWriter  # for logging to tensorboard\n",
    "from tqdm import tqdm\n",
    "\n",
    "# HCSDataModule makes it easy to load data during training.\n",
    "from viscy.data.hcs import HCSDataModule\n",
    "\n",
    "# Trainer class and UNet.\n",
    "from viscy.light.engine import MixedLoss, VSUNet\n",
    "from viscy.light.trainer import VSTrainer\n",
    "\n",
    "# training augmentations\n",
    "from viscy.transforms import (\n",
    "    NormalizeSampled,\n",
    "    RandAdjustContrastd,\n",
    "    RandAffined,\n",
    "    RandGaussianNoised,\n",
    "    RandGaussianSmoothd,\n",
    "    RandScaleIntensityd,\n",
    "    RandWeightedCropd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed random number generators for reproducibility.\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "# Paths to data and log directory\n",
    "# TODO: Change this to point to your data directory.\n",
    "top_dir = Path(f\"~/data\").expanduser()\n",
    "\n",
    "data_path = top_dir / \"img2img/training/a549_hoechst_cellmask_train_val.zarr\"\n",
    "log_dir = top_dir / \"img2img/logs/\"\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Data not found at {data_path}. Please check the top_dir and data_path variables.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log directory if needed, and launch tensorboard\n",
    "log_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf84694",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "\n",
    "The next cell starts tensorboard.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "If you launched jupyter lab from ssh terminal, add <code>--host &lt;your-server-name&gt;</code> to the tensorboard command below. <code>&lt;your-server-name&gt;</code> is the address of your compute node that ends in amazonaws.com.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "If you are using VSCode and a remote server, you will need to forward the port to view the tensorboard. <br>\n",
    "Take note of the port number was assigned in the previous cell.(i.e <code> http://localhost:{port_number_assigned}</code>) <br>\n",
    "\n",
    "Locate the your VSCode terminal and select the <code>Ports</code> tab <br>\n",
    "<ul>\n",
    "<li>Add a new port with the <code>port_number_assigned</code>\n",
    "</ul>\n",
    "Click on the link to view the tensorboard and it should open in your browser.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a951628",
   "metadata": {
    "tags": [],
    "title": "Setup tensorboard and port forwarding"
   },
   "outputs": [],
   "source": [
    "# Function to find an available port\n",
    "def find_free_port():\n",
    "    import socket\n",
    "\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind((\"\", 0))\n",
    "        return s.getsockname()[1]\n",
    "\n",
    "\n",
    "# Launch TensorBoard on the browser\n",
    "def launch_tensorboard(log_dir):\n",
    "    import subprocess\n",
    "\n",
    "    port = find_free_port()\n",
    "    tensorboard_cmd = f\"tensorboard --logdir={log_dir} --port={port}\"\n",
    "    process = subprocess.Popen(tensorboard_cmd, shell=True)\n",
    "    print(\n",
    "        f\"TensorBoard started at http://localhost:{port}. \\n\"\n",
    "        \"If you are using VSCode remote session, forward the port using the PORTS tab next to TERMINAL.\"\n",
    "    )\n",
    "    return process\n",
    "\n",
    "\n",
    "# Launch tensorboard and click on the link to view the logs.\n",
    "tensorboard_process = launch_tensorboard(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232bc22",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Load OME-Zarr Dataset\n",
    "\n",
    "There should be 34 FOVs in the dataset.\n",
    "\n",
    "Each FOV consists of 3 channels of 2048x2048 images,\n",
    "saved in the [High-Content Screening (HCS) layout](https://ngff.openmicroscopy.org/latest/#hcs-layout)\n",
    "specified by the Open Microscopy Environment Next Generation File Format\n",
    "(OME-NGFF).\n",
    "\n",
    "- The layout on the disk is: `row/col/field/pyramid_level/timepoint/channel/z/y/x.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5fa03",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "You can inspect the tree structure by using your terminal:\n",
    "<code> iohub info -v \"path-to-ome-zarr\" </code>\n",
    "\n",
    "<br>\n",
    "More info on the CLI:\n",
    "<code>iohub info --help </code> to see the help menu.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the python function called by `iohub info` CLI command\n",
    "print_info(data_path, verbose=True)\n",
    "\n",
    "# Open and inspect the dataset.\n",
    "dataset = open_ome_zarr(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6217d3a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Look at a couple different fields of view by changing the value in the cell above.\n",
    "Check the cell density, the cell morphologies, and fluorescence signal.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the field and pyramid_level below to visualize data.\n",
    "row = 0\n",
    "col = 0\n",
    "field = 9  # TODO: Change this to explore data.\n",
    "\n",
    "# This dataset contains images at 3 resolutions.\n",
    "# '0' is the highest resolution\n",
    "# '1' is down-scaled 2x2,\n",
    "# '2' is down-scaled 4x4.\n",
    "# Such datasets are called image pyramids.\n",
    "pyaramid_level = 0\n",
    "\n",
    "# `channel_names` is the metadata that is stored with data according to the OME-NGFF spec.\n",
    "n_channels = len(dataset.channel_names)\n",
    "\n",
    "image = dataset[f\"{row}/{col}/{field}/{pyaramid_level}\"].numpy()\n",
    "print(f\"data shape: {image.shape}, FOV: {field}, pyramid level: {pyaramid_level}\")\n",
    "\n",
    "figure, axes = plt.subplots(1, n_channels, figsize=(9, 3))\n",
    "\n",
    "for i in range(n_channels):\n",
    "    for i in range(n_channels):\n",
    "        channel_image = image[0, i, 0]\n",
    "        # Adjust contrast to 0.5th and 99.5th percentile of pixel values.\n",
    "        p_low, p_high = np.percentile(channel_image, (0.5, 99.5))\n",
    "        channel_image = np.clip(channel_image, p_low, p_high)\n",
    "        axes[i].imshow(channel_image, cmap=\"gray\")\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].set_title(dataset.channel_names[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcec7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_batch_tensorboard(batch, batchno, writer, card_name):\n",
    "    \"\"\"\n",
    "    Logs a batch of images to TensorBoard.\n",
    "\n",
    "    Args:\n",
    "        batch (dict): A dictionary containing the batch of images to be logged.\n",
    "        writer (SummaryWriter): A TensorBoard SummaryWriter object.\n",
    "        card_name (str): The name of the card to be displayed in TensorBoard.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    batch_phase = batch[\"source\"][:, :, 0, :, :]  # batch_size x z_size x Y x X tensor.\n",
    "    batch_membrane = batch[\"target\"][:, 1, 0, :, :].unsqueeze(\n",
    "        1\n",
    "    )  # batch_size x 1 x Y x X tensor.\n",
    "    batch_nuclei = batch[\"target\"][:, 0, 0, :, :].unsqueeze(\n",
    "        1\n",
    "    )  # batch_size x 1 x Y x X tensor.\n",
    "\n",
    "    p1, p99 = np.percentile(batch_membrane, (0.1, 99.9))\n",
    "    batch_membrane = np.clip((batch_membrane - p1) / (p99 - p1), 0, 1)\n",
    "\n",
    "    p1, p99 = np.percentile(batch_nuclei, (0.1, 99.9))\n",
    "    batch_nuclei = np.clip((batch_nuclei - p1) / (p99 - p1), 0, 1)\n",
    "\n",
    "    p1, p99 = np.percentile(batch_phase, (0.1, 99.9))\n",
    "    batch_phase = np.clip((batch_phase - p1) / (p99 - p1), 0, 1)\n",
    "\n",
    "    [N, C, H, W] = batch_phase.shape\n",
    "    interleaved_images = torch.zeros((3 * N, C, H, W), dtype=batch_phase.dtype)\n",
    "    interleaved_images[0::3, :] = batch_phase\n",
    "    interleaved_images[1::3, :] = batch_nuclei\n",
    "    interleaved_images[2::3, :] = batch_membrane\n",
    "\n",
    "    grid = torchvision.utils.make_grid(interleaved_images, nrow=3)\n",
    "\n",
    "    # add the grid to tensorboard\n",
    "    writer.add_image(card_name, grid, batchno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ddd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to visualize a batch on jupyter, in case tensorboard is finicky\n",
    "def log_batch_jupyter(batch):\n",
    "    \"\"\"\n",
    "    Logs a batch of images on jupyter using ipywidget.\n",
    "\n",
    "    Args:\n",
    "        batch (dict): A dictionary containing the batch of images to be logged.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    batch_phase = batch[\"source\"][:, :, 0, :, :]  # batch_size x z_size x Y x X tensor.\n",
    "    batch_size = batch_phase.shape[0]\n",
    "    batch_membrane = batch[\"target\"][:, 1, 0, :, :].unsqueeze(\n",
    "        1\n",
    "    )  # batch_size x 1 x Y x X tensor.\n",
    "    batch_nuclei = batch[\"target\"][:, 0, 0, :, :].unsqueeze(\n",
    "        1\n",
    "    )  # batch_size x 1 x Y x X tensor.\n",
    "\n",
    "    p1, p99 = np.percentile(batch_membrane, (0.1, 99.9))\n",
    "    batch_membrane = np.clip((batch_membrane - p1) / (p99 - p1), 0, 1)\n",
    "\n",
    "    p1, p99 = np.percentile(batch_nuclei, (0.1, 99.9))\n",
    "    batch_nuclei = np.clip((batch_nuclei - p1) / (p99 - p1), 0, 1)\n",
    "\n",
    "    p1, p99 = np.percentile(batch_phase, (0.1, 99.9))\n",
    "    batch_phase = np.clip((batch_phase - p1) / (p99 - p1), 0, 1)\n",
    "\n",
    "    plt.figure()\n",
    "    fig, axes = plt.subplots(\n",
    "        batch_size, n_channels, figsize=(n_channels * 2, batch_size * 2)\n",
    "    )\n",
    "    [N, C, H, W] = batch_phase.shape\n",
    "    for sample_id in range(batch_size):\n",
    "        axes[sample_id, 0].imshow(batch_phase[sample_id, 0])\n",
    "        axes[sample_id, 1].imshow(batch_nuclei[sample_id, 0])\n",
    "        axes[sample_id, 2].imshow(batch_membrane[sample_id, 0])\n",
    "\n",
    "        for i in range(n_channels):\n",
    "            axes[sample_id, i].axis(\"off\")\n",
    "            axes[sample_id, i].set_title(dataset.channel_names[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data module.\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# 4 is a perfectly reasonable batch size\n",
    "# (batch size does not have to be a power of 2)\n",
    "# See: https://sebastianraschka.com/blog/2022/batch-size-2.html\n",
    "\n",
    "data_module = HCSDataModule(\n",
    "    data_path,\n",
    "    z_window_size=1,\n",
    "    architecture=\"UNeXt2_2D\",\n",
    "    source_channel=[\"Phase3D\"],\n",
    "    target_channel=[\"Nucl\", \"Mem\"],\n",
    "    split_ratio=0.8,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=8,\n",
    "    yx_patch_size=(256, 256),  # larger patch size makes it easy to see augmentations.\n",
    "    augmentations=[],  # Turn off augmentation for now.\n",
    "    normalizations=[],  # Turn off normalization for now.\n",
    ")\n",
    "data_module.setup(\"fit\")\n",
    "\n",
    "source_channel = [\"Phase3D\"]\n",
    "target_channel = [\"Nucl\", \"Mem\"]\n",
    "\n",
    "augmentations = [\n",
    "    RandWeightedCropd(\n",
    "        keys=source_channel + target_channel,\n",
    "        spatial_size=(1, 384, 384),\n",
    "        num_samples=2,\n",
    "        w_key=target_channel[0],\n",
    "    ),\n",
    "    RandAffined(\n",
    "        keys=source_channel + target_channel,\n",
    "        rotate_range=[3.14, 0.0, 0.0],\n",
    "        scale_range=[0.0, 0.3, 0.3],\n",
    "        prob=0.8,\n",
    "        padding_mode=\"zeros\",\n",
    "        shear_range=[0.0, 0.01, 0.01],\n",
    "    ),\n",
    "    RandAdjustContrastd(keys=source_channel, prob=0.5, gamma=(0.8, 1.2)),\n",
    "    RandScaleIntensityd(keys=source_channel, factors=0.5, prob=0.5),\n",
    "    RandGaussianNoised(keys=source_channel, prob=0.5, mean=0.0, std=0.3),\n",
    "    RandGaussianSmoothd(\n",
    "        keys=source_channel,\n",
    "        sigma_x=(0.25, 0.75),\n",
    "        sigma_y=(0.25, 0.75),\n",
    "        sigma_z=(0.0, 0.0),\n",
    "        prob=0.5,\n",
    "    ),\n",
    "]\n",
    "\n",
    "normalizations = [\n",
    "    NormalizeSampled(\n",
    "        keys=source_channel + target_channel,\n",
    "        level=\"fov_statistics\",\n",
    "        subtrahend=\"mean\",\n",
    "        divisor=\"std\",\n",
    "    )\n",
    "]\n",
    "\n",
    "data_module.augmentations = augmentations\n",
    "data_module.augmentations = normalizations\n",
    "\n",
    "data_module.setup(\"fit\")\n",
    "\n",
    "# get the new data loader with augmentation turned on\n",
    "augmented_train_dataloader = data_module.train_dataloader()\n",
    "\n",
    "# Draw batches and write to tensorboard\n",
    "writer = SummaryWriter(log_dir=f\"{log_dir}/view_batch\")\n",
    "augmented_batch = next(iter(augmented_train_dataloader))\n",
    "log_batch_tensorboard(augmented_batch, 0, writer, \"augmentation/some\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac24fbb",
   "metadata": {},
   "source": [
    "Visualize directly on Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_batch_jupyter(augmented_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080b9230",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3>Train a 2D U-Net model to predict nuclei and membrane from phase.</h3><br>\n",
    "\n",
    "### Construct a 2D UNeXt2 using VisCy <br>\n",
    "See ``viscy.unet.networks.Unet2D.Unet2d`` ([source code](https://github.com/mehta-lab/VisCy/blob/7c5e4c1d68e70163cf514d22c475da8ea7dc3a88/viscy/unet/networks/Unet2D.py#L7)) for configuration details.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de413c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D UNet.\n",
    "GPU_ID = 0\n",
    "\n",
    "BATCH_SIZE = 12\n",
    "YX_PATCH_SIZE = (256, 256)\n",
    "\n",
    "# Dictionary that specifies key parameters of the model.\n",
    "\n",
    "phase2fluor_config = dict(\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    encoder_blocks=[3, 3, 9, 3],\n",
    "    dims=[96, 192, 384, 768],\n",
    "    decoder_conv_blocks=2,\n",
    "    stem_kernel_size=(1, 2, 2),\n",
    "    in_stack_depth=1,\n",
    "    pretraining=False,\n",
    ")\n",
    "\n",
    "phase2fluor_model = VSUNet(\n",
    "    architecture=\"UNeXt2_2D\",  # 2D UNeXt2 architecture\n",
    "    model_config=phase2fluor_config.copy(),\n",
    "    loss_function=MixedLoss(l1_alpha=0.5, l2_alpha=0.0, ms_dssim_alpha=0.5),\n",
    "    schedule=\"WarmupCosine\",\n",
    "    lr=6e-4,\n",
    "    log_batches_per_epoch=5,  # Number of samples from each batch to log to tensorboard.\n",
    "    freeze_encoder=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd5346d",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "### Instantiate data module and trainer, test that we are setup to launch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_channel = [\"Phase3D\"]\n",
    "target_channel = [\"Nucl\", \"Mem\"]\n",
    "# Setup the data module.\n",
    "phase2fluor_2D_data = HCSDataModule(\n",
    "    data_path,\n",
    "    architecture=\"UNeXt2_2D\",\n",
    "    source_channel=source_channel,\n",
    "    target_channel=target_channel,\n",
    "    z_window_size=1,\n",
    "    split_ratio=0.8,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=8,\n",
    "    yx_patch_size=YX_PATCH_SIZE,\n",
    "    augmentations=augmentations,\n",
    "    normalizations=normalizations,\n",
    ")\n",
    "phase2fluor_2D_data.setup(\"fit\")\n",
    "# fast_dev_run runs a single batch of data through the model to check for errors.\n",
    "trainer = VSTrainer(accelerator=\"gpu\", devices=[GPU_ID], fast_dev_run=True)\n",
    "\n",
    "# trainer class takes the model and the data module as inputs.\n",
    "trainer.fit(phase2fluor_model, datamodule=phase2fluor_2D_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f01b40",
   "metadata": {},
   "source": [
    "## View model graph.\n",
    "visualize graph of phase2fluor model as image.\n",
    "model_graph_phase2fluor = torchview.draw_graph(\n",
    "    phase2fluor_model,\n",
    "    phase2fluor_2D_data.train_dataset[0][\"source\"][0].unsqueeze(dim=0),\n",
    "    roll=True,\n",
    "    depth=3,  # adjust depth to zoom in.\n",
    "    device=\"cpu\",\n",
    "    # expand_nested=True,\n",
    ")\n",
    "Print the image of the model.\n",
    "model_graph_phase2fluor.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "# You can check by typing `nvidia-smi`\n",
    "GPU_ID = 0\n",
    "\n",
    "n_samples = len(phase2fluor_2D_data.train_dataset)\n",
    "steps_per_epoch = n_samples // BATCH_SIZE  # steps per epoch.\n",
    "n_epochs = 10  # Set this to 50 or the number of epochs you want to train for.\n",
    "\n",
    "trainer = VSTrainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[GPU_ID],\n",
    "    max_epochs=n_epochs,\n",
    "    log_every_n_steps=steps_per_epoch // 2,\n",
    "    # log losses and image samples 2 times per epoch.\n",
    "    logger=TensorBoardLogger(\n",
    "        save_dir=log_dir,\n",
    "        # lightning trainer transparently saves logs and model checkpoints in this directory.\n",
    "        name=\"phase2fluor\",\n",
    "        log_graph=True,\n",
    "    ),\n",
    ")\n",
    "# Launch training and check that loss and images are being logged on tensorboard.\n",
    "trainer.fit(phase2fluor_model, datamodule=phase2fluor_2D_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c2a7f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "Let's compute metrics directly and plot below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the test data module.\n",
    "test_data_path = top_dir / \"img2img/test/a549_hoechst_cellmask_test.zarr\"\n",
    "source_channel = [\"Phase3D\"]\n",
    "target_channel = [\"Nucl\", \"Mem\"]\n",
    "\n",
    "test_data = HCSDataModule(\n",
    "    test_data_path,\n",
    "    source_channel=source_channel,\n",
    "    target_channel=target_channel,\n",
    "    z_window_size=1,\n",
    "    batch_size=1,\n",
    "    num_workers=8,\n",
    "    architecture=\"UNeXt2\",\n",
    ")\n",
    "test_data.setup(\"test\")\n",
    "\n",
    "test_metrics = pd.DataFrame(\n",
    "    columns=[\"pearson_nuc\", \"SSIM_nuc\", \"pearson_mem\", \"SSIM_mem\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d74c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics directly and plot here.\n",
    "\n",
    "\n",
    "def min_max_scale(input):\n",
    "    return (input - np.min(input)) / (np.max(input) - np.min(input))\n",
    "\n",
    "\n",
    "def normalize_fov(input: ArrayLike):\n",
    "    \"Normalizing the fov with zero mean and unit variance\"\n",
    "    mean = np.mean(input)\n",
    "    std = np.std(input)\n",
    "    return (input - mean) / std\n",
    "\n",
    "\n",
    "for i, sample in enumerate(\n",
    "    tqdm(test_data.test_dataloader(), desc=\"Computing metrics per sample\")\n",
    "):\n",
    "    phase_image = sample[\"source\"]\n",
    "    with torch.inference_mode():  # turn off gradient computation.\n",
    "        predicted_image = phase2fluor_model(phase_image)\n",
    "\n",
    "    target_image = (\n",
    "        sample[\"target\"].cpu().numpy().squeeze(0)\n",
    "    )  # Squeezing batch dimension.\n",
    "    predicted_image = predicted_image.cpu().numpy().squeeze(0)\n",
    "    phase_image = phase_image.cpu().numpy().squeeze(0)\n",
    "    target_mem = min_max_scale(target_image[1, 0, :, :])\n",
    "    target_nuc = min_max_scale(target_image[0, 0, :, :])\n",
    "    # slicing channel dimension, squeezing z-dimension.\n",
    "    predicted_mem = min_max_scale(predicted_image[1, :, :, :].squeeze(0))\n",
    "    predicted_nuc = min_max_scale(predicted_image[0, :, :, :].squeeze(0))\n",
    "\n",
    "    # Compute SSIM and pearson correlation.\n",
    "    ssim_nuc = metrics.structural_similarity(target_nuc, predicted_nuc, data_range=1)\n",
    "    ssim_mem = metrics.structural_similarity(target_mem, predicted_mem, data_range=1)\n",
    "    pearson_nuc = np.corrcoef(target_nuc.flatten(), predicted_nuc.flatten())[0, 1]\n",
    "    pearson_mem = np.corrcoef(target_mem.flatten(), predicted_mem.flatten())[0, 1]\n",
    "\n",
    "    test_metrics.loc[i] = {\n",
    "        \"pearson_nuc\": pearson_nuc,\n",
    "        \"SSIM_nuc\": ssim_nuc,\n",
    "        \"pearson_mem\": pearson_mem,\n",
    "        \"SSIM_mem\": ssim_mem,\n",
    "    }\n",
    "\n",
    "test_metrics.boxplot(\n",
    "    column=[\"pearson_nuc\", \"SSIM_nuc\", \"pearson_mem\", \"SSIM_mem\"],\n",
    "    rot=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted image\n",
    "# Adjust the image to the 0.5-99.5 percentile range.\n",
    "def process_image(image):\n",
    "    p_low, p_high = np.percentile(image, (0.5, 99.5))\n",
    "    return np.clip(image, p_low, p_high)\n",
    "\n",
    "\n",
    "# Plot the predicted image vs target image.\n",
    "channel_titles = [\n",
    "    \"Phase\",\n",
    "    \"Target Nuclei\",\n",
    "    \"Target Membrane\",\n",
    "    \"Predicted Nuclei\",\n",
    "    \"Predicted Membrane\",\n",
    "]\n",
    "fig, axes = plt.subplots(5, 1, figsize=(20, 20))\n",
    "\n",
    "# Get a writer to output the images into tensorboard and plot the source, predictions and target images\n",
    "for i, sample in enumerate(test_data.test_dataloader()):\n",
    "    # Plot the phase image\n",
    "    phase_image = sample[\"source\"]\n",
    "    channel_image = phase_image[0, 0, 0]\n",
    "    p_low, p_high = np.percentile(channel_image, (0.5, 99.5))\n",
    "    channel_image = np.clip(channel_image, p_low, p_high)\n",
    "    axes[0].imshow(channel_image, cmap=\"gray\")\n",
    "    axes[0].set_title(channel_titles[0])\n",
    "\n",
    "    with torch.inference_mode():  # turn off gradient computation.\n",
    "        predicted_image = (\n",
    "            phase2fluor_model(phase_image.to(phase2fluor_model.device))\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "            .squeeze(0)\n",
    "        )\n",
    "\n",
    "    target_image = sample[\"target\"].cpu().numpy().squeeze(0)\n",
    "    phase_raw = process_image(phase_image[0, 0, 0])\n",
    "    predicted_nuclei = process_image(predicted_image[0, 0])\n",
    "    predicted_membrane = process_image(predicted_image[1, 0])\n",
    "    target_nuclei = process_image(target_image[0, 0])\n",
    "    target_membrane = process_image(target_image[1, 0])\n",
    "    # Concatenate all images side by side\n",
    "    combined_image = np.concatenate(\n",
    "        (\n",
    "            phase_raw,\n",
    "            predicted_nuclei,\n",
    "            predicted_membrane,\n",
    "            target_nuclei,\n",
    "            target_membrane,\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Plot the phase,target nuclei, target membrane, predicted nuclei, predicted membrane\n",
    "    axes[1].imshow(target_nuclei, cmap=\"gray\")\n",
    "    axes[1].set_title(channel_titles[1])\n",
    "    axes[2].imshow(target_membrane, cmap=\"gray\")\n",
    "    axes[2].set_title(channel_titles[2])\n",
    "    axes[3].imshow(predicted_nuclei, cmap=\"gray\")\n",
    "    axes[3].set_title(channel_titles[3])\n",
    "    axes[4].imshow(predicted_membrane, cmap=\"gray\")\n",
    "    axes[4].set_title(channel_titles[4])\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5545877",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "#<div class=\"alert alert-success\">\n",
    "\n",
    "<h2> Checkpoint 1 </h2>\n",
    "\n",
    "You have now trained and evaluated a phase to fluorescence model\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9344f9c",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<h2> Part 2: Train fluorescence to phase contrast translation model.</h2><br>\n",
    "Instantiate a data module, model, and trainer for fluorescence to phase contrast translation. Copy over the code from previous cells and update the parameters. Give the variables and paths a different name/suffix (fluor2phase) to avoid overwriting objects used to train phase2fluor models.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The entire training loop is contained in this cell.\n",
    "source_channel = [\"Mem\"]  # or 'Nuc' depending on choice\n",
    "target_channel = [\"Phase3D\"]\n",
    "YX_PATCH_SIZE = (256, 256)\n",
    "BATCH_SIZE = 12\n",
    "n_epochs = 50\n",
    "\n",
    "# Setup the new augmentations\n",
    "augmentations = [\n",
    "    RandWeightedCropd(\n",
    "        keys=source_channel + target_channel,\n",
    "        spatial_size=(1, 384, 384),\n",
    "        num_samples=2,\n",
    "        w_key=target_channel[0],\n",
    "    ),\n",
    "    RandAffined(\n",
    "        keys=source_channel + target_channel,\n",
    "        rotate_range=[3.14, 0.0, 0.0],\n",
    "        scale_range=[0.0, 0.3, 0.3],\n",
    "        prob=0.8,\n",
    "        padding_mode=\"zeros\",\n",
    "        shear_range=[0.0, 0.01, 0.01],\n",
    "    ),\n",
    "    RandAdjustContrastd(keys=source_channel, prob=0.5, gamma=(0.8, 1.2)),\n",
    "    RandScaleIntensityd(keys=source_channel, factors=0.5, prob=0.5),\n",
    "    RandGaussianNoised(keys=source_channel, prob=0.5, mean=0.0, std=0.3),\n",
    "    RandGaussianSmoothd(\n",
    "        keys=source_channel,\n",
    "        sigma_x=(0.25, 0.75),\n",
    "        sigma_y=(0.25, 0.75),\n",
    "        sigma_z=(0.0, 0.0),\n",
    "        prob=0.5,\n",
    "    ),\n",
    "]\n",
    "\n",
    "normalizations = [\n",
    "    NormalizeSampled(\n",
    "        keys=source_channel + target_channel,\n",
    "        level=\"fov_statistics\",\n",
    "        subtrahend=\"mean\",\n",
    "        divisor=\"std\",\n",
    "    )\n",
    "]\n",
    "\n",
    "# Setup the dataloader\n",
    "fluor2phase_data = HCSDataModule(\n",
    "    data_path,\n",
    "    architecture=\"UNeXt2_2D\",\n",
    "    source_channel=source_channel,\n",
    "    target_channel=target_channel,\n",
    "    z_window_size=1,\n",
    "    split_ratio=0.8,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=8,\n",
    "    yx_patch_size=YX_PATCH_SIZE,\n",
    "    augmentations=augmentations,\n",
    "    normalizations=normalizations,\n",
    ")\n",
    "fluor2phase_data.setup(\"fit\")\n",
    "\n",
    "n_samples = len(fluor2phase_data.train_dataset)\n",
    "\n",
    "steps_per_epoch = n_samples // BATCH_SIZE  # steps per epoch.\n",
    "\n",
    "# Dictionary that specifies key parameters of the model.\n",
    "fluor2phase_config = dict(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    encoder_blocks=[3, 3, 9, 3],\n",
    "    dims=[96, 192, 384, 768],\n",
    "    decoder_conv_blocks=2,\n",
    "    stem_kernel_size=(1, 2, 2),\n",
    "    in_stack_depth=1,\n",
    "    pretraining=False,\n",
    ")\n",
    "\n",
    "fluor2phase_model = VSUNet(\n",
    "    architecture=\"UNeXt2_2D\",\n",
    "    model_config=fluor2phase_config.copy(),\n",
    "    loss_function=MixedLoss(l1_alpha=0.5, l2_alpha=0.0, ms_dssim_alpha=0.5),\n",
    "    schedule=\"WarmupCosine\",\n",
    "    lr=6e-4,\n",
    "    log_batches_per_epoch=5,  # Number of samples from each batch to log to tensorboard.\n",
    "    freeze_encoder=False,\n",
    ")\n",
    "\n",
    "# Visualize the graph of fluor2phase model as image.\n",
    "model_graph_fluor2phase = torchview.draw_graph(\n",
    "    fluor2phase_model,\n",
    "    next(iter(fluor2phase_data.train_dataloader()))[\"source\"],\n",
    "    depth=3,  # adjust depth to zoom in.\n",
    "    device=\"cpu\",\n",
    ")\n",
    "model_graph_fluor2phase.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd6ee4",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "trainer = VSTrainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[GPU_ID],\n",
    "    max_epochs=n_epochs,\n",
    "    log_every_n_steps=steps_per_epoch // 2,\n",
    "    logger=TensorBoardLogger(\n",
    "        save_dir=log_dir,\n",
    "        # lightning trainer transparently saves logs and model checkpoints in this directory.\n",
    "        name=\"fluor2phase\",\n",
    "        log_graph=True,\n",
    "    ),\n",
    ")\n",
    "trainer.fit(fluor2phase_model, datamodule=fluor2phase_data)\n",
    "test_data_path = Path(\n",
    "    \"~/data/img2img/test/a549_hoechst_cellmask_test.zarr\"\n",
    ").expanduser()\n",
    "\n",
    "test_data = HCSDataModule(\n",
    "    test_data_path,\n",
    "    source_channel=\"Mem\",  # or Nuc, depending on your choice of source\n",
    "    target_channel=\"Phase3D\",\n",
    "    z_window_size=1,\n",
    "    batch_size=1,\n",
    "    num_workers=8,\n",
    "    architecture=\"UNeXt2\",\n",
    ")\n",
    "test_data.setup(\"test\")\n",
    "\n",
    "test_metrics = pd.DataFrame(columns=[\"pearson_phase\", \"SSIM_phase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73abd3b1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "for i, sample in enumerate(test_data.test_dataloader()):\n",
    "    source_image = sample[\"source\"]\n",
    "    with torch.inference_mode():  # turn off gradient computation.\n",
    "        predicted_image = fluor2phase_model(source_image.to(fluor2phase_model.device))\n",
    "\n",
    "    target_image = (\n",
    "        sample[\"target\"].cpu().numpy().squeeze(0)\n",
    "    )  # Squeezing batch dimension.\n",
    "    predicted_image = predicted_image.cpu().numpy().squeeze(0)\n",
    "    source_image = source_image.cpu().numpy().squeeze(0)\n",
    "    target_phase = min_max_scale(target_image[0, 0, :, :])\n",
    "    # slicing channel dimension, squeezing z-dimension.\n",
    "    predicted_phase = min_max_scale(predicted_image[0, :, :, :].squeeze(0))\n",
    "\n",
    "    # Compute SSIM and pearson correlation.\n",
    "    ssim_phase = metrics.structural_similarity(\n",
    "        target_phase, predicted_phase, data_range=1\n",
    "    )\n",
    "    pearson_phase = np.corrcoef(target_phase.flatten(), predicted_phase.flatten())[0, 1]\n",
    "\n",
    "    test_metrics.loc[i] = {\n",
    "        \"pearson_phase\": pearson_phase,\n",
    "        \"SSIM_phase\": ssim_phase,\n",
    "    }\n",
    "\n",
    "test_metrics.boxplot(\n",
    "    column=[\"pearson_phase\", \"SSIM_phase\"],\n",
    "    rot=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d276b8ab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot the predicted image\n",
    "channel_titles = [\n",
    "    \"Membrane\",\n",
    "    \"Target Phase\",\n",
    "    \"Predicted_Phase\",\n",
    "]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 20))\n",
    "\n",
    "for i, sample in enumerate(test_data.test_dataloader()):\n",
    "    # Plot the phase image\n",
    "    mem_image = sample[\"source\"]\n",
    "    channel_image = mem_image[0, 0, 0]\n",
    "    p_low, p_high = np.percentile(channel_image, (0.5, 99.5))\n",
    "    channel_image = np.clip(channel_image, p_low, p_high)\n",
    "    axes[0].imshow(channel_image, cmap=\"gray\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[0].set_title(channel_titles[0])\n",
    "\n",
    "    with torch.inference_mode():  # turn off gradient computation.\n",
    "        predicted_image = (\n",
    "            phase2fluor_model(phase_image.to(phase2fluor_model.device))\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "            .squeeze(0)\n",
    "        )\n",
    "\n",
    "    target_image = sample[\"target\"].cpu().numpy().squeeze(0)\n",
    "    # Plot the predicted images\n",
    "    channel_image = target_image[0, 0]\n",
    "    p_low, p_high = np.percentile(channel_image, (0.5, 99.5))\n",
    "    channel_image = np.clip(channel_image, p_low, p_high)\n",
    "    axes[1].imshow(channel_image, cmap=\"gray\")\n",
    "    axes[1].axis(\"off\")\n",
    "    axes[1].set_title(channel_titles[1])\n",
    "\n",
    "    channel_image = predicted_image[1, 0]\n",
    "    p_low, p_high = np.percentile(channel_image, (0.1, 99.5))\n",
    "    channel_image = np.clip(channel_image, p_low, p_high)\n",
    "    axes[2].imshow(channel_image, cmap=\"gray\")\n",
    "    axes[2].axis(\"off\")\n",
    "    axes[2].set_title(f\"VS {channel_titles[2]}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "phase2fluor_config = dict(\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    encoder_blocks=[3, 3, 9, 3],\n",
    "    dims=[96, 192, 384, 768],\n",
    "    decoder_conv_blocks=2,\n",
    "    stem_kernel_size=(1, 2, 2),\n",
    "    in_stack_depth=1,\n",
    "    pretraining=False,\n",
    ")\n",
    "\n",
    "phase2fluor_model_low_lr = VSUNet(\n",
    "    architecture=\"UNeXt2_2D\",\n",
    "    model_config=phase2fluor_config.copy(),\n",
    "    loss_function=MixedLoss(\n",
    "        l1_alpha=0.5, l2_alpha=0.0, ms_dssim_alpha=0.5\n",
    "    ),  # Changed the loss function to MixedLoss L1 and MS-SSIM\n",
    "    schedule=\"WarmupCosine\",\n",
    "    lr=2e-5,  # lower learning rate by factor of 10\n",
    "    log_batches_per_epoch=5,  # Number of samples from each batch to log to tensorboard.\n",
    ")\n",
    "\n",
    "trainer = VSTrainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[GPU_ID],\n",
    "    max_epochs=n_epochs,\n",
    "    log_every_n_steps=steps_per_epoch,\n",
    "    logger=TensorBoardLogger(\n",
    "        save_dir=log_dir,\n",
    "        name=\"phase2fluor\",\n",
    "        version=\"phase2fluor_low_lr\",\n",
    "        log_graph=True,\n",
    "    ),\n",
    "    fast_dev_run=True,\n",
    ")  # Set fast_dev_run to False to train the model.\n",
    "trainer.fit(phase2fluor_model_low_lr, datamodule=phase2fluor_2D_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca08583",
   "metadata": {
    "cell_marker": "\"\"\"",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2> \n",
    "ðŸŽ‰ The end of the notebook ðŸŽ‰\n",
    "</h2>\n",
    "\n",
    "Congratulations! You have trained several image translation models now!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
