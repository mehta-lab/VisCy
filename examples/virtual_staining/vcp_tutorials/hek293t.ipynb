{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f9de9f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Cytoland Tutorial: Virtual Staining of HEK293T Cells with VSCyto3D\n",
    "\n",
    "**Estimated time to complete:** 15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35604f88",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Learning Goals\n",
    "\n",
    "* Download the VSCyto3D model and an example dataset containing HEK293T cell images.\n",
    "* Pre-compute normalization statistics the images using the `viscy preprocess` command line interface (CLI).\n",
    "* Run inference for joint virtual staining of cell nuclei and plasma membrane via the `viscy predict` CLI.\n",
    "* Visualize and compare virtually and experimentally stained cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e901541",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Prerequisites\n",
    "\n",
    "Python>=3.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f737d",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Introduction\n",
    "\n",
    "See the [model card](https://virtualcellmodels.cziscience.com/paper/cytoland2025)\n",
    "for more details about the Cytoland models. \n",
    "\n",
    "VSCyto3D is a 3D UNeXt2 model that has been trained on A549, HEK293T, and hiPSC cells.\n",
    "This model enables users to jointly stain cell nuclei and plasma membranes from 3D label-free images\n",
    "to for downstream analysis such as cell segmentation and tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be27a008",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Setup\n",
    "\n",
    "The commands below will install the required packages and download the example dataset and model checkpoint.\n",
    "It may take a few minutes to download all the files.\n",
    "\n",
    "## Setup Google Colab\n",
    "\n",
    "To run this quick-start guide using Google Colab,\n",
    "choose the 'T4' GPU runtime from the \"Connect\" dropdown menu\n",
    "in the upper-right corner of this notebook for faster execution.\n",
    "Using a GPU significantly speeds up running model inference, but CPU compute can also be used.\n",
    "\n",
    "## Setup Local Environment\n",
    "\n",
    "The commands below assume a Unix-like shell with `wget` installed.\n",
    "On Windows, the files can be downloaded manually from the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install VisCy with the optional dependencies for this example\n",
    "# See the [repository](https://github.com/mehta-lab/VisCy) for more details\n",
    "# Here stackview and ipycanvas are installed for visualization\n",
    "!pip install -U \"viscy[metrics,visual]==0.3.0rc3\" stackview ipycanvas==0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44290fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel if running in Google Colab\n",
    "if \"get_ipython\" in globals():\n",
    "    session = get_ipython()\n",
    "    if \"google.colab\" in str(session):\n",
    "        print(\"Shutting down colab session.\")\n",
    "        session.kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09279795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the example dataset\n",
    "!wget -m -np -nH --cut-dirs=5 -R \"index.html*\" \"https://public.czbiohub.org/comp.micro/viscy/VS_datasets/VSCyto3D/test/HEK293T-Phase3D-H2B-CAAX-example.zarr/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25794437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the downloaded dataset to what the prediction coinfig expects\n",
    "# And validate the OME-Zarr metadata with iohub\n",
    "!mv HEK293T-Phase3D-H2B-CAAX-example.zarr input.ome.zarr\n",
    "!iohub info -v input.ome.zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the VSCyto3D model checkpoint and prediction config\n",
    "!wget \"https://public.czbiohub.org/comp.micro/viscy/VS_models/VSCyto3D/epoch=83-step=14532-loss=0.492.ckpt\"\n",
    "!wget \"https://public.czbiohub.org/comp.micro/viscy/VS_models/VSCyto3D/predict.yml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e739c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Use Case\n",
    "\n",
    "## Example Dataset\n",
    "\n",
    "The HEK293T example dataset used in this quick-start guide contains\n",
    "quantitative phase and paired fluorescence images of cell nuclei and plasma membrane.\n",
    "It is a subset (one cropped region of interest) a test set used to evaluate the VSCyto3D model.\n",
    "The full dataset can be downloaded from the\n",
    "[BioImage Archive](https://www.ebi.ac.uk/biostudies/BioImages/studies/S-BIAD1702).\n",
    "\n",
    "Refer to our [preprint](https://doi.org/10.1101/2024.05.31.596901) for more details\n",
    "about how the dataset and model were generated.\n",
    "\n",
    "## Using Custom Data\n",
    "\n",
    "The model only requires label-free images for inference.\n",
    "To run inference on your own data,\n",
    "convert them into the OME-Zarr data format using iohub or other\n",
    "[tools](https://ngff.openmicroscopy.org/tools/index.html#file-conversion),\n",
    "and edit the `predict.yml` file to specify the input data path.\n",
    "The image may need to be resampled to roughly match the voxel size of the example dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6425fdbb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Run Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d25ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the CLI command to pre-compute normalization statistics\n",
    "!viscy preprocess --data_path=input.ome.zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9fa697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the CLI command to run inference\n",
    "# This will take about 2 minutes on Google Colab (T4 GPU)\n",
    "!viscy predict -c predict.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9473df3b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Analysis of Model Outputs\n",
    "\n",
    "Visualize the experimental and virtually stained images using the `stackview` package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f73d0a1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Visualizing large 3D multichannel images in a Jupyter notebook is prone to performance issues\n",
    "and may crash the notebook if the images are too large\n",
    "(the free Colab instances have limited CPU cores and memory).\n",
    "The visualization code below is only intended for demonstration.\n",
    "We strongly recommend downloading the images\n",
    "and using a standalone viewer such as [napari](https://napari.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9bbd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import stackview\n",
    "from iohub import open_ome_zarr\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "try:\n",
    "    from google.colab import output\n",
    "\n",
    "    output.enable_custom_widget_manager()\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the images\n",
    "def split_and_rescale_channels(timepoint: np.ndarray) -> tuple[np.ndarray, ...]:\n",
    "    return (rescale_intensity(channel, out_range=(0, 1)) for channel in timepoint)\n",
    "\n",
    "\n",
    "fov_name = \"plate/0/11\"\n",
    "input_image = open_ome_zarr(\"input.ome.zarr\")[fov_name][\"0\"]\n",
    "prediction_image = open_ome_zarr(\"prediction.ome.zarr\")[fov_name][\"0\"]\n",
    "\n",
    "phase, fluor_nucleus, fluor_membrane = split_and_rescale_channels(input_image[0])\n",
    "vs_nucleus, vs_membrane = split_and_rescale_channels(prediction_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4fe50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drag the slider to start rendering\n",
    "# Click on the numbered buttons to toggle the channels\n",
    "stackview.switch(\n",
    "    images=[phase, fluor_nucleus, fluor_membrane, vs_nucleus, vs_membrane],\n",
    "    colormap=[\"gray\", \"pure_green\", \"pure_magenta\", \"pure_blue\", \"pure_yellow\"],\n",
    "    toggleable=True,\n",
    "    zoom_factor=0.5,\n",
    "    display_min=0.0,\n",
    "    display_max=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302fa29a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Summary\n",
    "\n",
    "In the above example, we demonstrated how to use the VSCyto3D model to stain cell nuclei and plasma membranes.\n",
    "Note how the experimental fluorescence is missing for a subset of cells.\n",
    "This is due to loss of genetic labeling.\n",
    "The virtually stained images is not affected by this issue and can robustly label all cells."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
