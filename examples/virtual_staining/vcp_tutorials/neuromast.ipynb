{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb7ee801",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Cytoland Tutorial: Virtual Staining of Zebrafish Neuromasts with VSNeuromast\n",
    "\n",
    "**Estimated time to complete:** 15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df05a79",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Learning Goals\n",
    "\n",
    "* Download the VSNeuromast model and an example dataset containing time-lapse images of zebrafish neuromasts.\n",
    "* Pre-compute normalization statistics for the images using the `viscy preprocess` command-line interface (CLI).\n",
    "* Run inference for joint virtual staining of cell nuclei and plasma membrane via the `viscy predict` CLI.\n",
    "* Visualize the effect of photobleaching in fluorescence imaging and how virtual staining can mitigate this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e5585",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Prerequisites\n",
    "\n",
    "Python>=3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e67a9e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The zebrafish neuromasts are sensory organs on the lateral lines.\n",
    "Given their relatively simple structure and high accessibility to live imaging,\n",
    "they are used as a model system to study organogenesis _in vivo_.\n",
    "However, multiplexed long-term fluorescence imaging at high spatial-temporal resolution\n",
    "is often limited by photobleaching and phototoxicity.\n",
    "Also, engineering fish lines with a combination of landmark fluorescent labels\n",
    "(e.g. nuclei and plasma membrane) and functional reporters increases experimental complexity.\n",
    "\\\n",
    "VSNeuromast is a 3D UNeXt2 model that has been trained zebrafish neuromasts using the Cytoland approach.\n",
    "(See the [model card](https://virtualcellmodels.cziscience.com/paper/cytoland2025)\n",
    "for more details about the Cytoland models.)\n",
    "This model enables users to jointly stain cell nuclei and plasma membranes from 3D label-free images\n",
    "for downstream analysis such as cell segmentation and tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b348eff",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Setup\n",
    "\n",
    "The commands below will install the required packages and download the example dataset and model checkpoint.\n",
    "It may take a **few minutes** to download all the files.\n",
    "\n",
    "## Setup Google Colab\n",
    "\n",
    "To run this quick-start guide using Google Colab,\n",
    "choose the 'T4' GPU runtime from the \"Connect\" dropdown menu\n",
    "in the upper-right corner of this notebook for faster execution.\n",
    "Using a GPU significantly speeds up running model inference, but CPU compute can also be used.\n",
    "\n",
    "## Setup Local Environment\n",
    "\n",
    "The commands below assume a Unix-like shell with `wget` installed.\n",
    "On Windows, the files can be downloaded manually from the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install VisCy with the optional dependencies for this example\n",
    "# See the [repository](https://github.com/mehta-lab/VisCy) for more details\n",
    "# Here stackview and ipycanvas are installed for visualization\n",
    "!pip install -U \"viscy[metrics,visual]==0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db49b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart kernel if running in Google Colab\n",
    "# This is required to use the packages installed above\n",
    "# The 'kernel crashed' message is expected here\n",
    "if \"get_ipython\" in globals():\n",
    "    session = get_ipython()\n",
    "    if \"google.colab\" in str(session):\n",
    "        print(\"Shutting down colab session.\")\n",
    "        session.kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdad5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the example dataset\n",
    "!wget -m -np -nH --cut-dirs=5 -R \"index.html*\" \"https://public.czbiohub.org/comp.micro/viscy/VS_datasets/VSNeuromast/test/isim-bleaching-example.zarr/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the downloaded dataset to what the example prediction config expects (`input.ome.zarr`)\n",
    "# And validate the OME-Zarr metadata with iohub\n",
    "!mv isim-bleaching-example.zarr input.ome.zarr\n",
    "!iohub info -v input.ome.zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a74e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the VSNeuromast model checkpoint and prediction config\n",
    "!wget \"https://public.czbiohub.org/comp.micro/viscy/VS_models/VSNeuromast/epoch=64-step=24960.ckpt\"\n",
    "!wget \"https://public.czbiohub.org/comp.micro/viscy/VS_models/VSNeuromast/predict.yml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee415cf9",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Use Case\n",
    "\n",
    "## Example Dataset\n",
    "\n",
    "The neuromast example dataset used in this tutorial contains\n",
    "quantitative phase and paired fluorescence images of cell nuclei and plasma membrane.\n",
    "It is a subsampled time-lapse from a test set used to evaluate the VSNeuromast model.\n",
    "The full dataset can be downloaded from the\n",
    "[BioImage Archive](https://www.ebi.ac.uk/biostudies/BioImages/studies/S-BIAD1702).\n",
    "\n",
    "Refer to our [preprint](https://doi.org/10.1101/2024.05.31.596901) for more details\n",
    "about how the dataset and model were generated.\n",
    "\n",
    "## Using Custom Data\n",
    "\n",
    "The model only requires label-free images for inference.\n",
    "To run inference on your own data,\n",
    "convert them into the OME-Zarr data format using iohub or other\n",
    "[tools](https://ngff.openmicroscopy.org/tools/index.html#file-conversion),\n",
    "and edit the `predict.yml` file to specify the input data path.\n",
    "Specifically, the `data.init_args.data_path` field should be updated:\n",
    "\n",
    "```diff\n",
    "-     data_path: input.ome.zarr\n",
    "+     data_path: /path/to/your.ome.zarr\n",
    "```\n",
    "\n",
    "The image may need to be resampled to roughly match the voxel size of the example dataset\n",
    "(0.2x0.1x0.1 Âµm, ZYX)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c072c813",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Run Model Inference\n",
    "\n",
    "On Google Colab, the preprocessing step takes about **1 minute**,\n",
    "and the inference step takes about **2 minutes** (T4 GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the CLI command to pre-compute normalization statistics\n",
    "# This includes the median and interquartile range (IQR)\n",
    "# Used to shift and scale the intensity distribution of the input images\n",
    "!viscy preprocess --data_path=input.ome.zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cec6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the CLI command to run inference\n",
    "!viscy predict -c predict.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c910f98",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Analysis of Model Outputs\n",
    "\n",
    "Measure photobleaching in the fluorescence images\n",
    "and how virtual staining can mitigate this issue."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
