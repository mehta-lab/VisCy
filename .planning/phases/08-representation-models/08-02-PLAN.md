---
phase: 08-representation-models
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/viscy-models/src/viscy_models/vae/__init__.py
  - packages/viscy-models/src/viscy_models/vae/beta_vae_25d.py
  - packages/viscy-models/src/viscy_models/vae/beta_vae_monai.py
  - packages/viscy-models/tests/test_vae/__init__.py
  - packages/viscy-models/tests/test_vae/test_beta_vae_25d.py
  - packages/viscy-models/tests/test_vae/test_beta_vae_monai.py
autonomous: true

must_haves:
  truths:
    - "from viscy_models.vae import BetaVae25D works"
    - "from viscy_models.vae import BetaVaeMonai works"
    - "BetaVae25D forward pass returns SimpleNamespace with recon_x, mean, logvar, z attributes"
    - "BetaVaeMonai forward pass returns SimpleNamespace with recon_x, mean, logvar, z attributes"
    - "BetaVae25D reconstruction output matches input spatial dimensions"
    - "BetaVaeMonai reconstruction output matches input spatial dimensions"
    - "Forward-pass tests pass for both VAE models"
  artifacts:
    - path: "packages/viscy-models/src/viscy_models/vae/beta_vae_25d.py"
      provides: "VaeUpStage, VaeEncoder, VaeDecoder, BetaVae25D classes"
      contains: "class BetaVae25D"
    - path: "packages/viscy-models/src/viscy_models/vae/beta_vae_monai.py"
      provides: "BetaVaeMonai class"
      contains: "class BetaVaeMonai"
    - path: "packages/viscy-models/src/viscy_models/vae/__init__.py"
      provides: "Public re-exports for vae subpackage"
      contains: "BetaVae25D"
    - path: "packages/viscy-models/tests/test_vae/test_beta_vae_25d.py"
      provides: "Forward-pass tests for BetaVae25D"
      contains: "test_beta_vae_25d"
    - path: "packages/viscy-models/tests/test_vae/test_beta_vae_monai.py"
      provides: "Forward-pass tests for BetaVaeMonai"
      contains: "test_beta_vae_monai"
  key_links:
    - from: "vae/beta_vae_25d.py"
      to: "components/stems.py"
      via: "import StemDepthtoChannels"
      pattern: "from viscy_models.components.stems import StemDepthtoChannels"
    - from: "vae/beta_vae_25d.py"
      to: "components/heads.py"
      via: "import PixelToVoxelHead"
      pattern: "from viscy_models.components.heads import PixelToVoxelHead"
    - from: "vae/__init__.py"
      to: "vae/beta_vae_25d.py"
      via: "re-export BetaVae25D"
      pattern: "from viscy_models.vae.beta_vae_25d import BetaVae25D"
    - from: "vae/__init__.py"
      to: "vae/beta_vae_monai.py"
      via: "re-export BetaVaeMonai"
      pattern: "from viscy_models.vae.beta_vae_monai import BetaVaeMonai"
---

<objective>
Migrate BetaVae25D and BetaVaeMonai to viscy-models with forward-pass tests.

Purpose: Satisfies VAE-01, VAE-02, VAE-03 requirements. Both VAE models become importable from `viscy_models.vae` with comprehensive forward-pass tests verifying output structure (reconstruction, mu, logvar, z).

Output: Two model files (including VaeUpStage/VaeEncoder/VaeDecoder helpers in beta_vae_25d.py), updated __init__.py, and test files with forward-pass verification.
</objective>

<execution_context>
@/Users/eduardo.hirata/.claude/get-shit-done/workflows/execute-plan.md
@/Users/eduardo.hirata/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-representation-models/08-RESEARCH.md
@packages/viscy-models/src/viscy_models/components/stems.py
@packages/viscy-models/src/viscy_models/components/heads.py
@packages/viscy-models/tests/conftest.py
@packages/viscy-models/tests/test_unet/test_unext2.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Migrate BetaVae25D and BetaVaeMonai to vae module</name>
  <files>
    packages/viscy-models/src/viscy_models/vae/beta_vae_25d.py
    packages/viscy-models/src/viscy_models/vae/beta_vae_monai.py
    packages/viscy-models/src/viscy_models/vae/__init__.py
  </files>
  <action>
Retrieve the original source code from pre-monorepo commit:
```
git show fe7a5da^:viscy/representation/vae.py
```

**beta_vae_25d.py** -- Create `vae/beta_vae_25d.py` containing four classes in order: VaeUpStage, VaeEncoder, VaeDecoder, BetaVae25D. Copy all four classes verbatim from original with these specific changes:

1. Import changes (the ONLY structural changes):
   - Replace `from viscy.unet.networks.unext2 import PixelToVoxelHead, StemDepthtoChannels` with:
     ```python
     from viscy_models.components.heads import PixelToVoxelHead
     from viscy_models.components.stems import StemDepthtoChannels
     ```
   - Keep all other imports identical (timm, torch, monai blocks, SimpleNamespace, etc.)

2. Fix VaeDecoder mutable defaults (COMPAT-02):
   - Change `decoder_channels: list[int] = [1024, 512, 256, 128]` to `decoder_channels: Sequence[int] = (1024, 512, 256, 128)`
   - Change `strides: list[int] = [2, 2, 2, 1]` to `strides: Sequence[int] = (2, 2, 2, 1)`
   - Ensure `Sequence` is imported from `collections.abc` (already in original imports)

3. Change VaeEncoder `pretrained` parameter default from `True` to `False` (pure nn.Module semantics, consistent with UNeXt2 and ContrastiveEncoder patterns).

4. Preserve ALL attribute names exactly for state dict compatibility:
   - BetaVae25D: `self.encoder`, `self.decoder`
   - VaeEncoder: `self.stem`, `self.encoder`, `self.fc`, `self.fc_mu`, `self.fc_logvar`
   - VaeDecoder: `self.latent_reshape`, `self.latent_proj`, `self.decoder_stages`, `self.head`
   - VaeUpStage: `self.upsample`, `self.conv`

5. Preserve SimpleNamespace return type for both VaeEncoder.forward() and BetaVae25D.forward(). Do NOT change return types.

6. Preserve the BetaVae25D constructor logic for computing decoder_channels and strides from encoder properties. Do NOT refactor the strides list construction `[2] * decoder_stages + [1]` (extra element is intentional per original).

**beta_vae_monai.py** -- Create `vae/beta_vae_monai.py` containing BetaVaeMonai class. Copy verbatim from original. This model has NO viscy imports -- only monai and torch. No changes needed beyond placing in new file. Preserve `self.model` attribute name. Preserve SimpleNamespace return type.

**__init__.py** -- Update `vae/__init__.py`:

```python
"""Variational autoencoder architectures."""

from viscy_models.vae.beta_vae_25d import BetaVae25D
from viscy_models.vae.beta_vae_monai import BetaVaeMonai

__all__ = ["BetaVae25D", "BetaVaeMonai"]
```

Ensure ruff D-series docstring compliance on all files (single-line summary ending with period, blank line before description).
  </action>
  <verify>
Run: `cd /Users/eduardo.hirata/Documents/repos/VisCy && uv run --package viscy-models python -c "from viscy_models.vae import BetaVae25D, BetaVaeMonai; print('OK')"` succeeds.
Run: `cd /Users/eduardo.hirata/Documents/repos/VisCy && uv run --package viscy-models python -c "from viscy_models.vae.beta_vae_25d import VaeEncoder, VaeDecoder, VaeUpStage; print('OK')"` succeeds.
  </verify>
  <done>
BetaVae25D and BetaVaeMonai are importable from `viscy_models.vae`. Helper classes VaeUpStage, VaeEncoder, VaeDecoder remain in beta_vae_25d.py (not in components). VaeDecoder mutable defaults fixed to tuples. VaeEncoder pretrained defaults to False. All attribute names preserved for state dict compatibility.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create forward-pass tests for VAE models</name>
  <files>
    packages/viscy-models/tests/test_vae/__init__.py
    packages/viscy-models/tests/test_vae/test_beta_vae_25d.py
    packages/viscy-models/tests/test_vae/test_beta_vae_monai.py
  </files>
  <action>
Create `tests/test_vae/__init__.py` as empty file.

**test_beta_vae_25d.py** -- Forward-pass tests for BetaVae25D:

1. `test_beta_vae_25d_resnet50(device)`: ResNet50 backbone, in_channels=2, in_stack_depth=16, out_stack_depth=16, latent_dim=256, input_spatial_size=(128, 128), stem_kernel_size=(2, 4, 4), stem_stride=(2, 4, 4), decoder_stages=3. Input: `(2, 2, 16, 128, 128)`. Assert:
   - `out.recon_x.shape == (2, 2, 16, 128, 128)`
   - `out.mean.shape == (2, 256)`
   - `out.logvar.shape == (2, 256)`
   - `out.z.shape == (2, 256)`
   Use `model.eval()` + `torch.no_grad()`. Batch size 2.

2. `test_beta_vae_25d_convnext(device)`: ConvNeXt-tiny backbone, in_channels=1, in_stack_depth=15, out_stack_depth=15, latent_dim=256, input_spatial_size=(128, 128), stem_kernel_size=(5, 4, 4), stem_stride=(5, 4, 4), decoder_stages=3. Input: `(2, 1, 15, 128, 128)`. Assert:
   - `out.recon_x.shape == (2, 1, 15, 128, 128)`
   - `out.mean.shape == (2, 256)`
   - `out.logvar.shape == (2, 256)`
   - `out.z.shape == (2, 256)`

All BetaVae25D tests: Import from `viscy_models.vae import BetaVae25D`. Verify return is SimpleNamespace with all four attributes (recon_x, mean, logvar, z). Use `model.eval()` + `torch.no_grad()`.

**test_beta_vae_monai.py** -- Forward-pass tests for BetaVaeMonai:

1. `test_beta_vae_monai_2d(device)`: spatial_dims=2, in_shape=(1, 64, 64), out_channels=1, latent_size=128, channels=(32, 64), strides=(2, 2). Input: `(2, 1, 64, 64)`. Assert:
   - `out.recon_x.shape == (2, 1, 64, 64)`
   - `out.mean.shape == (2, 128)`
   - `out.logvar.shape == (2, 128)`
   - `out.z.shape == (2, 128)`

2. `test_beta_vae_monai_3d(device)`: spatial_dims=3, in_shape=(1, 32, 32, 32), out_channels=1, latent_size=64, channels=(16, 32), strides=(2, 2). Input: `(2, 1, 32, 32, 32)`. Assert:
   - `out.recon_x.shape == (2, 1, 32, 32, 32)`
   - `out.mean.shape == (2, 64)`
   - `out.logvar.shape == (2, 64)`
   - `out.z.shape == (2, 64)`

All BetaVaeMonai tests: Import from `viscy_models.vae import BetaVaeMonai`. Verify return is SimpleNamespace with all four attributes (recon_x, mean, logvar, z). Use `model.eval()` + `torch.no_grad()`. Batch size 2.
  </action>
  <verify>
Run: `cd /Users/eduardo.hirata/Documents/repos/VisCy && uv run --package viscy-models pytest packages/viscy-models/tests/test_vae/ -v` -- all tests pass.
  </verify>
  <done>
4 forward-pass tests pass: 2 for BetaVae25D (resnet50, convnext_tiny) and 2 for BetaVaeMonai (2D, 3D). Tests verify SimpleNamespace output structure with recon_x, mean, logvar, z attributes and correct shapes.
  </done>
</task>

</tasks>

<verification>
1. `uv run --package viscy-models python -c "from viscy_models.vae import BetaVae25D, BetaVaeMonai"` succeeds
2. `uv run --package viscy-models pytest packages/viscy-models/tests/test_vae/ -v` -- all 4 tests pass
3. State dict keys verified: BetaVae25D has encoder, decoder; BetaVaeMonai has model
4. VaeDecoder defaults are tuples not lists (COMPAT-02)
</verification>

<success_criteria>
- BetaVae25D importable from `viscy_models.vae` with resnet50 and convnext_tiny backbone support
- BetaVaeMonai importable from `viscy_models.vae` with 2D and 3D spatial dimension support
- VaeUpStage, VaeEncoder, VaeDecoder stay in vae/beta_vae_25d.py (not in components)
- VaeDecoder mutable defaults fixed to tuples (COMPAT-02)
- 4 forward-pass tests pass covering both models with multiple configurations
- SimpleNamespace return type preserved with recon_x, mean, logvar, z attributes
- All attribute names preserved for state dict compatibility
- VaeEncoder pretrained defaults to False for pure nn.Module semantics
</success_criteria>

<output>
After completion, create `.planning/phases/08-representation-models/08-02-SUMMARY.md`
</output>
