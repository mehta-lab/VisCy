---
phase: 21-cell-index-lineage
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - applications/dynaclr/src/dynaclr/index.py
  - applications/dynaclr/tests/test_index.py
autonomous: true

must_haves:
  truths:
    - "MultiExperimentIndex builds a flat tracks DataFrame from all registered experiments with one row per cell observation per timepoint"
    - "Each row has columns: experiment, condition, global_track_id, hours_post_infection, well_name, fluorescence_channel, lineage_id, position, fov_name, track_id, t, y, x, z"
    - "Lineage is reconstructed -- daughter tracks have lineage_id equal to their parent track, allowing temporal positive sampling through division events"
    - "Border cells are retained by clamping crop centroids inward -- cells near edges get shifted patch origins instead of being excluded"
    - "Cells whose centroids are completely outside the image boundary are excluded"
  artifacts:
    - path: "applications/dynaclr/src/dynaclr/index.py"
      provides: "MultiExperimentIndex class with tracks DataFrame, lineage reconstruction, border clamping"
      min_lines: 120
    - path: "applications/dynaclr/tests/test_index.py"
      provides: "TDD test suite for MultiExperimentIndex tracks, lineage, border clamping"
      min_lines: 150
  key_links:
    - from: "applications/dynaclr/src/dynaclr/index.py"
      to: "dynaclr.experiment.ExperimentRegistry"
      via: "import and __init__ parameter"
      pattern: "from dynaclr\\.experiment import.*ExperimentRegistry"
    - from: "applications/dynaclr/src/dynaclr/index.py"
      to: "iohub.ngff"
      via: "open_ome_zarr for reading positions and image dimensions"
      pattern: "from iohub\\.ngff import open_ome_zarr"
    - from: "applications/dynaclr/tests/test_index.py"
      to: "applications/dynaclr/src/dynaclr/index.py"
      via: "import MultiExperimentIndex"
      pattern: "from dynaclr\\.index import MultiExperimentIndex"
---

<objective>
TDD: MultiExperimentIndex tracks building with lineage reconstruction and border clamping (CELL-01, CELL-02, CELL-03).

Purpose: Build the core cell observation index that unifies tracking data across multiple experiments into a single DataFrame with experiment metadata, lineage links, and border-safe centroids. This is the foundation for all downstream sampling in the composable framework.

Output: `index.py` with MultiExperimentIndex class, `test_index.py` with comprehensive test suite.
</objective>

<execution_context>
@/Users/eduardo.hirata/.claude/get-shit-done/workflows/execute-plan.md
@/Users/eduardo.hirata/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/20-experiment-configuration/20-01-SUMMARY.md
@applications/dynaclr/src/dynaclr/experiment.py
@packages/viscy-data/src/viscy_data/_typing.py
</context>

<feature>
  <name>MultiExperimentIndex: tracks building, lineage, border clamping</name>
  <files>applications/dynaclr/src/dynaclr/index.py, applications/dynaclr/tests/test_index.py</files>

  <behavior>
    MultiExperimentIndex.__init__(registry, z_range, yx_patch_size, include_wells, exclude_fovs) builds self.tracks DataFrame.

    **CELL-01: Unified tracks DataFrame**

    For each experiment in registry.experiments:
      1. Open zarr store at exp.data_path via iohub.ngff.open_ome_zarr
      2. Iterate positions (FOVs), filtering by include_wells and exclude_fovs
      3. For each position, read the tracking CSV from exp.tracks_path / well_name / fov_idx / tracks.csv (pattern: exp.tracks_path / fov.zgroup.name.strip("/") then glob for *.csv)
      4. Enrich each tracks table with columns:
         - "experiment": exp.name
         - "condition": resolved from exp.condition_wells (well_name -> condition label)
         - "well_name": extracted from position path (e.g. "A/1")
         - "fov_name": position.zgroup.name.strip("/") (e.g. "A/1/0")
         - "global_track_id": "{exp.name}_{fov_name}_{track_id}" (experiment-prefixed for uniqueness across experiments)
         - "hours_post_infection": exp.start_hpi + (row["t"] * exp.interval_minutes / 60)
         - "fluorescence_channel": exp.source_channel[1] if len(exp.source_channel) > 1 else "" (the non-phase channel name)
         - "position": the iohub Position object (for later data loading)
      5. Store Position handles in self.positions list
    6. pd.concat all enriched tables -> self.tracks, reset_index(drop=True)

    Required final columns: track_id, t, y, x, z, position, fov_name, well_name, experiment, condition, global_track_id, hours_post_infection, fluorescence_channel, lineage_id

    Test cases:
    - 2 experiments, 2 wells each, 2 FOVs each -> tracks has all observations
    - "experiment" column matches exp.name
    - "condition" column correctly maps wells to conditions
    - "global_track_id" is "{exp_name}_{fov_name}_{track_id}"
    - "hours_post_infection" = start_hpi + t * interval_minutes / 60
    - include_wells filters to only specified wells
    - exclude_fovs removes specified FOVs

    **CELL-02: Lineage reconstruction**

    After building the tracks DataFrame:
    1. Add "lineage_id" column initialized to global_track_id (each track is its own lineage by default)
    2. For tracks that have a non-NaN parent_track_id:
       - Find the parent's global_track_id within the same experiment+fov
       - Look up the parent's lineage_id
       - Set this track's lineage_id to the parent's lineage_id
    3. This means: root track -> lineage_id = own global_track_id. Daughter tracks -> lineage_id = root ancestor's global_track_id.
    4. Implementation approach: Build a parent->child graph per experiment+fov, then traverse from roots to propagate lineage_id.

    Test cases:
    - Track without parent_track_id -> lineage_id = own global_track_id
    - Track with parent_track_id -> lineage_id = parent's lineage_id
    - Chain: grandparent -> parent -> child, all share grandparent's lineage_id
    - parent_track_id references track not in data -> lineage_id = own global_track_id (graceful fallback)

    **CELL-03: Border clamping**

    Instead of excluding border cells (like TripletDataset._filter_tracks does), clamp centroids inward:
    1. For each position, get image dimensions (height, width) from position["0"]
    2. y_half, x_half = yx_patch_size[0] // 2, yx_patch_size[1] // 2
    3. Clamp: y_clamped = clip(y, y_half, height - y_half); x_clamped = clip(x, x_half, width - x_half)
    4. Store clamped values as "y_clamp" and "x_clamp" columns (keep original y, x for reference)
    5. Only exclude cells whose centroid is completely outside the image: y < 0 or y >= height or x < 0 or x >= width

    Test cases:
    - Cell at center (y=32, x=32 in 64x64 image, patch=32x32) -> y_clamp=32, x_clamp=32 (unchanged)
    - Cell near border (y=5, x=5) -> y_clamp=16, x_clamp=16 (clamped inward)
    - Cell at exact edge (y=0, x=0) -> y_clamp=16, x_clamp=16 (clamped)
    - Cell outside image (y=-5) -> excluded from tracks
    - All border cells retained (count check vs. old exclusion approach)
  </behavior>

  <implementation>
    File: applications/dynaclr/src/dynaclr/index.py

    ```python
    from __future__ import annotations

    import logging
    from pathlib import Path

    import numpy as np
    import pandas as pd
    from iohub.ngff import Position, open_ome_zarr

    from dynaclr.experiment import ExperimentRegistry

    _logger = logging.getLogger(__name__)

    __all__ = ["MultiExperimentIndex"]


    class MultiExperimentIndex:
        """Unified cell observation index across multiple experiments.

        Builds a flat DataFrame (self.tracks) with one row per cell observation
        per timepoint, enriched with experiment metadata, lineage links, and
        border-clamped centroids.
        """

        def __init__(
            self,
            registry: ExperimentRegistry,
            z_range: slice,
            yx_patch_size: tuple[int, int],
            include_wells: list[str] | None = None,
            exclude_fovs: list[str] | None = None,
        ) -> None:
            self.registry = registry
            self.z_range = z_range
            self.yx_patch_size = yx_patch_size

            positions, tracks_dfs = self._load_all_experiments(
                include_wells=include_wells, exclude_fovs=exclude_fovs
            )
            self.positions = positions
            tracks = pd.concat(tracks_dfs, ignore_index=True) if tracks_dfs else pd.DataFrame()
            tracks = self._reconstruct_lineage(tracks)
            tracks = self._clamp_borders(tracks)
            self.tracks = tracks.reset_index(drop=True)

        # ------- internal methods -------

        def _load_all_experiments(self, include_wells, exclude_fovs):
            """Load positions and enriched tracks for every experiment."""
            all_positions = []
            all_tracks = []
            for exp in self.registry.experiments:
                plate = open_ome_zarr(exp.data_path, mode="r")
                for pos_path, position in plate.positions():
                    fov_name = position.zgroup.name.strip("/")
                    # well_name is the first two path components (e.g. "A/1")
                    parts = fov_name.split("/")
                    well_name = "/".join(parts[:2])

                    if include_wells is not None and well_name not in include_wells:
                        continue
                    if exclude_fovs is not None and fov_name in exclude_fovs:
                        continue

                    # Resolve condition from experiment's condition_wells
                    condition = self._resolve_condition(exp, well_name)

                    # Read tracking CSV
                    tracks_dir = Path(exp.tracks_path) / fov_name
                    csv_files = list(tracks_dir.glob("*.csv"))
                    if not csv_files:
                        _logger.warning("No tracking CSV in %s, skipping", tracks_dir)
                        continue
                    tracks_df = pd.read_csv(csv_files[0])

                    # Enrich columns
                    tracks_df["experiment"] = exp.name
                    tracks_df["condition"] = condition
                    tracks_df["well_name"] = well_name
                    tracks_df["fov_name"] = fov_name
                    tracks_df["global_track_id"] = (
                        exp.name + "_" + fov_name + "_" + tracks_df["track_id"].astype(str)
                    )
                    tracks_df["hours_post_infection"] = (
                        exp.start_hpi + tracks_df["t"] * exp.interval_minutes / 60.0
                    )
                    fluorescence_ch = exp.source_channel[1] if len(exp.source_channel) > 1 else ""
                    tracks_df["fluorescence_channel"] = fluorescence_ch
                    tracks_df["position"] = [position] * len(tracks_df)

                    # Store image dims for border clamping
                    image = position["0"]
                    tracks_df["_img_height"] = image.height
                    tracks_df["_img_width"] = image.width

                    all_positions.append(position)
                    all_tracks.append(tracks_df)

            return all_positions, all_tracks

        @staticmethod
        def _resolve_condition(exp, well_name):
            """Map well_name to condition label from exp.condition_wells."""
            for condition_label, wells in exp.condition_wells.items():
                if well_name in wells:
                    return condition_label
            return "unknown"

        @staticmethod
        def _reconstruct_lineage(tracks):
            """Add lineage_id column linking daughters to root ancestor."""
            if tracks.empty:
                tracks["lineage_id"] = pd.Series(dtype=str)
                return tracks

            # Default: each track is its own lineage
            tracks["lineage_id"] = tracks["global_track_id"].copy()

            if "parent_track_id" not in tracks.columns:
                return tracks

            # Build parent->child mapping per experiment+fov
            for (exp, fov), group in tracks.groupby(["experiment", "fov_name"]):
                # Map track_id -> global_track_id within this FOV
                tid_to_gtid = dict(zip(group["track_id"], group["global_track_id"]))

                # Build parent graph: child_gtid -> parent_gtid
                parent_map = {}
                for _, row in group.drop_duplicates("track_id").iterrows():
                    ptid = row.get("parent_track_id")
                    if pd.notna(ptid) and int(ptid) in tid_to_gtid:
                        parent_map[row["global_track_id"]] = tid_to_gtid[int(ptid)]

                # Chase to root for each track
                def find_root(gtid):
                    visited = set()
                    current = gtid
                    while current in parent_map and current not in visited:
                        visited.add(current)
                        current = parent_map[current]
                    return current

                mask = tracks["experiment"] == exp
                mask &= tracks["fov_name"] == fov
                for gtid in group["global_track_id"].unique():
                    root = find_root(gtid)
                    tracks.loc[mask & (tracks["global_track_id"] == gtid), "lineage_id"] = root

            return tracks

        def _clamp_borders(self, tracks):
            """Clamp centroids inward instead of excluding border cells."""
            if tracks.empty:
                return tracks

            y_half = self.yx_patch_size[0] // 2
            x_half = self.yx_patch_size[1] // 2

            # Exclude cells completely outside image
            valid = (
                (tracks["y"] >= 0) & (tracks["y"] < tracks["_img_height"])
                & (tracks["x"] >= 0) & (tracks["x"] < tracks["_img_width"])
            )
            tracks = tracks[valid].copy()

            # Clamp inward
            tracks["y_clamp"] = tracks["y"].clip(lower=y_half, upper=tracks["_img_height"] - y_half)
            tracks["x_clamp"] = tracks["x"].clip(lower=x_half, upper=tracks["_img_width"] - x_half)

            # Drop internal columns
            tracks = tracks.drop(columns=["_img_height", "_img_width"])

            return tracks
    ```

    Test fixtures: Create 2 mini OME-Zarr stores with 2 wells x 2 FOVs each, and matching tracking CSV files with:
    - 5 tracks per FOV, 10 timepoints
    - Some tracks with parent_track_id (lineage)
    - Some cells near borders (y=2 or x=2 in 64x64 image)
    - One cell outside image boundary (y=-1) to test exclusion

    Use the pattern from test_experiment.py: @pytest.fixture with tmp_path, iohub.ngff.open_ome_zarr for store creation.
  </implementation>
</feature>

<verification>
- `cd /Users/eduardo.hirata/Documents/repos/VisCy && uv run --package dynaclr pytest applications/dynaclr/tests/test_index.py -v` -- all tests pass
- `uv run --package dynaclr python -c "from dynaclr.index import MultiExperimentIndex; print('OK')"` -- import works
- Tracks DataFrame has all required columns: experiment, condition, global_track_id, hours_post_infection, well_name, fluorescence_channel, lineage_id, position, fov_name, track_id, t, y, x, z, y_clamp, x_clamp
</verification>

<success_criteria>
- MultiExperimentIndex builds flat tracks DataFrame from 2+ experiments with correct column enrichment
- Lineage reconstruction correctly links daughter tracks to parent lineage_id
- Border cells are clamped inward (not excluded) with y_clamp/x_clamp columns
- Cells completely outside image boundary are excluded
- All tests pass with TDD RED->GREEN->REFACTOR cycle
</success_criteria>

<output>
After completion, create `.planning/phases/21-cell-index-lineage/21-01-SUMMARY.md`
</output>
