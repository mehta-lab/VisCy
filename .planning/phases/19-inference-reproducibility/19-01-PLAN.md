---
phase: 19-inference-reproducibility
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - applications/dynacrl/pyproject.toml
  - applications/dynacrl/tests/conftest.py
  - applications/dynacrl/tests/test_inference_reproducibility.py
  - uv.lock
autonomous: true
requirements: [INFER-01, INFER-02, INFER-03, TEST-01, TEST-02]

must_haves:
  truths:
    - "ContrastiveModule loads the pretrained checkpoint (epoch=104) without state dict key mismatches"
    - "Running trainer.predict with EmbeddingWriter writes an AnnData zarr to disk with features (X) and projections (obsm/X_projections)"
    - "Predicted features (X) are numerically identical to reference features (atol=0, rtol=0 or allclose with tight tolerance)"
    - "Predicted projections (obsm/X_projections) are numerically identical to reference projections"
    - "All tests are permanent pytest tests in applications/dynacrl/tests/"
    - "Tests are runnable via uv run --package dynacrl pytest and gracefully skip if HPC paths or GPU unavailable"
  artifacts:
    - path: "applications/dynacrl/tests/conftest.py"
      provides: "Shared HPC path fixtures, GPU availability, skip markers"
    - path: "applications/dynacrl/tests/test_inference_reproducibility.py"
      provides: "3 integration tests: checkpoint loading, embedding writing, exact match comparison"
  key_links:
    - from: "applications/dynacrl/tests/test_inference_reproducibility.py"
      to: "dynacrl.engine.ContrastiveModule"
      via: "checkpoint loading and predict_step"
      pattern: "ContrastiveModule.*ckpt_path"
    - from: "applications/dynacrl/tests/test_inference_reproducibility.py"
      to: "viscy_utils.callbacks.embedding_writer.EmbeddingWriter"
      via: "Trainer callback for writing predictions"
      pattern: "EmbeddingWriter.*output_path"
    - from: "applications/dynacrl/tests/test_inference_reproducibility.py"
      to: "reference zarr at /hpc/projects/.../timeaware_phase_160patch_104ckpt.zarr"
      via: "anndata.read_zarr comparison"
      pattern: "np\\.allclose.*ref.*pred"
---

<objective>
Create permanent integration tests that prove the modular DynaCLR application produces identical inference results to the original monolithic VisCy.

Purpose: Validate end-to-end inference reproducibility — checkpoint loading, embedding prediction, and numerical exactness — as the final validation gate for the v2.1 modularization.

Output: `test_inference_reproducibility.py` with 3 GPU+HPC integration tests that auto-skip when resources unavailable.
</objective>

<execution_context>
@/home/eduardo.hirata/.claude/get-shit-done/workflows/execute-plan.md
@/home/eduardo.hirata/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-training-validation/18-01-SUMMARY.md

Key reference files:
@applications/dynacrl/src/dynacrl/engine.py (ContrastiveModule with predict_step)
@packages/viscy-utils/src/viscy_utils/callbacks/embedding_writer.py (EmbeddingWriter callback)
@applications/dynacrl/tests/test_training_integration.py (existing test patterns)
@applications/dynacrl/pyproject.toml (current test dependencies)

Critical external paths (all verified to exist on HPC):
- Checkpoint: /hpc/projects/organelle_phenotyping/models/SEC61_TOMM20_G3BP1_Sensor/time_interval/dynaclr_gfp_rfp_Ph/organelle_sensor_phase_maxproj_ver3_150epochs/saved_checkpoints/epoch=104-step=53760.ckpt
- Reference embeddings: /hpc/projects/intracellular_dashboard/organelle_dynamics/2025_07_22_A549_SEC61_TOMM20_G3BP1_ZIKV/4-phenotyping/predictions/DynaCLR-2D-BagOfChannels-timeaware/v3/timeaware_phase_160patch_104ckpt.zarr
- Data zarr: /hpc/projects/intracellular_dashboard/organelle_dynamics/2025_07_22_A549_SEC61_TOMM20_G3BP1_ZIKV/4-phenotyping/train-test/2025_07_22_A549_SEC61_TOMM20_G3BP1_ZIKV.zarr
- Tracks zarr: /hpc/projects/intracellular_dashboard/organelle_dynamics/2025_07_22_A549_SEC61_TOMM20_G3BP1_ZIKV/1-preprocess/label-free/3-track/2025_07_22_A549_SEC61_TOMM20_G3BP1_ZIKV_cropped.zarr

Model config (from original predict_phase.yml):
- backbone: convnext_tiny, in_channels: 1, in_stack_depth: 1
- stem_kernel_size: [1, 4, 4], stem_stride: [1, 4, 4]
- embedding_dim: 768, projection_dim: 32, drop_path_rate: 0.0
- source_channel: [Phase3D], z_range: [0, 1], batch_size: 64
- initial_yx_patch_size: [160, 160], final_yx_patch_size: [160, 160]
- normalization: NormalizeSampled(keys=[Phase3D], level=fov_statistics, subtrahend=mean, divisor=std)
- seed_everything: 42, precision: 32-true, inference_mode: true

Reference output shape: X=[39170, 768] (float32), obsm/X_projections=[39170, 32] (float32)
Checkpoint state dict: 194 keys, all prefixed with `model.` (matches ContrastiveModule's self.model = encoder)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add test dependencies and create conftest with HPC fixtures</name>
  <files>
    applications/dynacrl/pyproject.toml
    applications/dynacrl/tests/conftest.py
    uv.lock
  </files>
  <action>
1. Add `anndata` to the `[dependency-groups].test` list in `applications/dynacrl/pyproject.toml`. anndata is needed to read the reference AnnData zarr for comparison. Run `uv lock` to update `uv.lock`.

2. Create `applications/dynacrl/tests/conftest.py` with:

   - Define path constants at module level:
     ```python
     CHECKPOINT_PATH = Path("/hpc/projects/organelle_phenotyping/models/SEC61_TOMM20_G3BP1_Sensor/time_interval/dynaclr_gfp_rfp_Ph/organelle_sensor_phase_maxproj_ver3_150epochs/saved_checkpoints/epoch=104-step=53760.ckpt")
     REFERENCE_ZARR_PATH = Path("/hpc/projects/intracellular_dashboard/organelle_dynamics/2025_07_22_A549_SEC61_TOMM20_G3BP1_ZIKV/4-phenotyping/predictions/DynaCLR-2D-BagOfChannels-timeaware/v3/timeaware_phase_160patch_104ckpt.zarr")
     DATA_ZARR_PATH = Path("/hpc/projects/intracellular_dashboard/organelle_dynamics/2025_07_22_A549_SEC61_TOMM20_G3BP1_ZIKV/4-phenotyping/train-test/2025_07_22_A549_SEC61_TOMM20_G3BP1_ZIKV.zarr")
     TRACKS_ZARR_PATH = Path("/hpc/projects/intracellular_dashboard/organelle_dynamics/2025_07_22_A549_SEC61_TOMM20_G3BP1_ZIKV/1-preprocess/label-free/3-track/2025_07_22_A549_SEC61_TOMM20_G3BP1_ZIKV_cropped.zarr")
     ```

   - Define `HPC_PATHS_AVAILABLE` boolean: `all(p.exists() for p in [CHECKPOINT_PATH, REFERENCE_ZARR_PATH, DATA_ZARR_PATH, TRACKS_ZARR_PATH])`

   - Define `GPU_AVAILABLE` boolean: `torch.cuda.is_available()`

   - Register a custom pytest marker `hpc_integration` via `pytest_configure`:
     ```python
     def pytest_configure(config):
         config.addinivalue_line("markers", "hpc_integration: requires HPC paths and GPU")
     ```

   - Create a `requires_hpc` fixture or use a skip decorator. The simplest approach: define a module-level skip condition that tests can use:
     ```python
     requires_hpc_and_gpu = pytest.mark.skipif(
         not (HPC_PATHS_AVAILABLE and GPU_AVAILABLE),
         reason="Requires HPC data paths and CUDA GPU"
     )
     ```

   - Export a `checkpoint_path` fixture returning CHECKPOINT_PATH.
   - Export a `reference_zarr_path` fixture returning REFERENCE_ZARR_PATH.
   - Export a `data_zarr_path` fixture returning DATA_ZARR_PATH.
   - Export a `tracks_zarr_path` fixture returning TRACKS_ZARR_PATH.

3. Verify with `uv run --package dynacrl python -c "import anndata; print(anndata.__version__)"`.
  </action>
  <verify>
    - `uv run --package dynacrl python -c "import anndata; print(anndata.__version__)"` succeeds
    - `applications/dynacrl/tests/conftest.py` exists and imports without error
    - Existing tests still pass: `uv run --package dynacrl pytest applications/dynacrl/tests/test_engine.py applications/dynacrl/tests/test_training_integration.py -v`
  </verify>
  <done>
    - anndata is a test dependency for dynacrl
    - conftest.py defines HPC path constants, skip conditions, and fixtures
    - All existing tests still pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Create inference reproducibility integration tests</name>
  <files>
    applications/dynacrl/tests/test_inference_reproducibility.py
  </files>
  <action>
Create `applications/dynacrl/tests/test_inference_reproducibility.py` with 3 tests. Import the skip marker and fixtures from conftest. All 3 tests are decorated with `@requires_hpc_and_gpu` so they gracefully skip in CI or when HPC paths are unavailable.

**Test 1: `test_checkpoint_loads_into_modular_contrastive_module`** (INFER-01)
- Instantiate `ContrastiveEncoder` with: `backbone="convnext_tiny"`, `in_channels=1`, `in_stack_depth=1`, `stem_kernel_size=[1, 4, 4]`, `stem_stride=[1, 4, 4]`, `embedding_dim=768`, `projection_dim=32`, `drop_path_rate=0.0`
- Instantiate `ContrastiveModule(encoder=encoder, example_input_array_shape=[1, 1, 1, 160, 160])`
- Load checkpoint: `ckpt = torch.load(checkpoint_path, map_location="cpu")` and call `module.load_state_dict(ckpt["state_dict"])`
- Assert `load_state_dict` returns no missing or unexpected keys (strict=True is default)
- Run a forward pass with a random tensor `torch.randn(1, 1, 1, 160, 160)` and assert features shape is `(1, 768)` and projections shape is `(1, 32)`

**Test 2: `test_predict_writes_embeddings`** (INFER-02)
- Build the same encoder and module as Test 1, load checkpoint
- Set up `TripletDataModule` with the exact config from original predict_phase.yml:
  - `data_path=data_zarr_path`, `tracks_path=tracks_zarr_path`
  - `source_channel=["Phase3D"]`, `z_range=[0, 1]`, `batch_size=64`
  - `num_workers=16`, `initial_yx_patch_size=[160, 160]`, `final_yx_patch_size=[160, 160]`
  - `normalizations=[NormalizeSampled(keys=["Phase3D"], level="fov_statistics", subtrahend="mean", divisor="std")]`
- Set up `EmbeddingWriter(output_path=tmp_path / "test_embeddings.zarr", phate_kwargs=None, pca_kwargs=None, umap_kwargs=None)` — disable dimensionality reductions for speed
- Create `Trainer(accelerator="gpu", devices=1, precision="32-true", callbacks=[writer], inference_mode=True, enable_progress_bar=False, logger=False)`
- Call `lightning.seed_everything(42)` before predict
- Run `trainer.predict(module, datamodule=datamodule)`
- Assert output zarr exists at `tmp_path / "test_embeddings.zarr"`
- Read with `anndata.read_zarr(...)`, assert X shape is `(39170, 768)` and `obsm["X_projections"]` shape is `(39170, 32)`

**Test 3: `test_embeddings_exact_match_with_reference`** (INFER-03)
- This test builds on Test 2 logic. Reuse the same setup (extract a helper function `_run_prediction(tmp_path, checkpoint_path, data_zarr_path, tracks_zarr_path)` to avoid duplication, or combine with Test 2 if cleaner).
- Read reference embeddings: `ref = anndata.read_zarr(reference_zarr_path)`
- Read predicted embeddings: `pred = anndata.read_zarr(tmp_path / "test_embeddings.zarr")`
- Compare features: `np.testing.assert_allclose(pred.X, ref.X, rtol=1e-5, atol=1e-5)` — use a tight tolerance. If GPU nondeterminism prevents exact match, use `rtol=1e-4, atol=1e-4` and document why.
- Compare projections: `np.testing.assert_allclose(pred.obsm["X_projections"], ref.obsm["X_projections"], rtol=1e-5, atol=1e-5)`
- Compare observation metadata: assert `pred.obs["fov_name"]` matches `ref.obs["fov_name"]` and `pred.obs["id"]` matches `ref.obs["id"]` (verifying sample ordering is preserved)
- Do NOT compare X_pca, X_phate, or X_umap — these are post-hoc reductions and may vary

**IMPORTANT implementation details:**
- Since Test 2 and Test 3 both need the prediction output and running prediction takes significant time on 39170 samples, combine them into a single test function OR use a session-scoped fixture. The most practical approach: create a single test `test_predict_embeddings_and_exact_match` that runs prediction once, then asserts both write success and numerical match. This saves ~30 min of redundant GPU compute. But keep the assertions clearly separated with descriptive comments for each requirement (INFER-02 section, INFER-03 section).
- Alternatively, use pytest fixtures with `scope="module"` to cache the prediction output path.
- Use `lightning.seed_everything(42)` to match the original config's `seed_everything: 42`.
- Use `precision="32-true"` to match original config.
- Use `inference_mode=True` in the Trainer to match original.
- Note: The TripletDataModule uses `collate_fn=lambda x: x` which produces list-of-dicts batches. The predict_step in ContrastiveModule handles `batch["anchor"]` which works because MONAI's ThreadDataLoader with this collate_fn stacks the samples automatically. This is an existing pattern that works.
  </action>
  <verify>
    - If on HPC with GPU: `uv run --package dynacrl pytest applications/dynacrl/tests/test_inference_reproducibility.py -v` — all tests pass
    - If NOT on HPC or no GPU: `uv run --package dynacrl pytest applications/dynacrl/tests/test_inference_reproducibility.py -v` — all tests are SKIPPED with clear reason
    - Full suite: `uv run --package dynacrl pytest -v` — all tests pass (6 existing + 2-3 new, with HPC tests either passing or skipping)
  </verify>
  <done>
    - test_checkpoint_loads_into_modular_contrastive_module passes (INFER-01)
    - test_predict_embeddings_and_exact_match passes: writes zarr AND matches reference (INFER-02 + INFER-03)
    - All tests live in applications/dynacrl/tests/ (TEST-01)
    - Full suite runs via `uv run --package dynacrl pytest` (TEST-02)
    - Tests skip gracefully when HPC paths or GPU unavailable
  </done>
</task>

</tasks>

<verification>
1. Checkpoint loading: `ContrastiveModule.load_state_dict(ckpt["state_dict"])` returns no missing/unexpected keys
2. Embedding output: AnnData zarr written with correct shapes (39170x768 features, 39170x32 projections)
3. Exact match: `np.testing.assert_allclose` passes for both X and obsm/X_projections against reference
4. Test suite: `uv run --package dynacrl pytest -v` shows all tests passing (existing + new)
5. Skip behavior: Without HPC/GPU, inference tests show as SKIPPED, not FAILED
</verification>

<success_criteria>
- A pretrained checkpoint loads into modular ContrastiveModule without state dict mismatches (INFER-01)
- Predict step with EmbeddingWriter writes embeddings to disk (INFER-02)
- Predicted embeddings numerically match reference outputs (INFER-03)
- All tests are permanent pytest tests in applications/dynacrl/tests/ (TEST-01)
- Full suite passes via `uv run --package dynacrl pytest` (TEST-02)
</success_criteria>

<output>
After completion, create `.planning/phases/19-inference-reproducibility/19-01-SUMMARY.md`
</output>
