---
phase: 09-legacy-unet-models
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/viscy-models/src/viscy_models/unet/unet2d.py
  - packages/viscy-models/src/viscy_models/unet/unet25d.py
  - packages/viscy-models/src/viscy_models/unet/__init__.py
  - packages/viscy-models/tests/test_unet/test_unet2d.py
  - packages/viscy-models/tests/test_unet/test_unet25d.py
autonomous: true

must_haves:
  truths:
    - "from viscy_models.unet import Unet2d works and produces correct 5D output shape"
    - "from viscy_models.unet import Unet25d works and produces correct 5D output shape"
    - "Unet2d state dict keys match legacy checkpoint format (down_conv_block_N, up_conv_block_N, etc.)"
    - "Unet25d state dict keys match legacy format including skip_conv_layer_N"
    - "Existing 46 tests still pass (no regressions)"
    - "New Unet2d tests pass for variable depth, residual, reg/seg task modes"
    - "New Unet25d tests pass for depth compression and depth preservation"
  artifacts:
    - path: "packages/viscy-models/src/viscy_models/unet/unet2d.py"
      provides: "Unet2d nn.Module class"
      contains: "class Unet2d"
    - path: "packages/viscy-models/src/viscy_models/unet/unet25d.py"
      provides: "Unet25d nn.Module class"
      contains: "class Unet25d"
    - path: "packages/viscy-models/src/viscy_models/unet/__init__.py"
      provides: "Public API exporting all 4 unet models"
      contains: "Unet2d"
    - path: "packages/viscy-models/tests/test_unet/test_unet2d.py"
      provides: "Pytest tests for Unet2d"
      contains: "def test_unet2d"
    - path: "packages/viscy-models/tests/test_unet/test_unet25d.py"
      provides: "Pytest tests for Unet25d"
      contains: "def test_unet25d"
  key_links:
    - from: "packages/viscy-models/src/viscy_models/unet/unet2d.py"
      to: "packages/viscy-models/src/viscy_models/unet/_layers/conv_block_2d.py"
      via: "import ConvBlock2D"
      pattern: "from viscy_models\\.unet\\._layers\\.conv_block_2d import ConvBlock2D"
    - from: "packages/viscy-models/src/viscy_models/unet/unet25d.py"
      to: "packages/viscy-models/src/viscy_models/unet/_layers/conv_block_3d.py"
      via: "import ConvBlock3D"
      pattern: "from viscy_models\\.unet\\._layers\\.conv_block_3d import ConvBlock3D"
    - from: "packages/viscy-models/src/viscy_models/unet/__init__.py"
      to: "packages/viscy-models/src/viscy_models/unet/unet2d.py"
      via: "re-export Unet2d"
      pattern: "from viscy_models\\.unet\\.unet2d import Unet2d"
    - from: "packages/viscy-models/src/viscy_models/unet/__init__.py"
      to: "packages/viscy-models/src/viscy_models/unet/unet25d.py"
      via: "re-export Unet25d"
      pattern: "from viscy_models\\.unet\\.unet25d import Unet25d"
---

<objective>
Migrate Unet2d and Unet25d from the v0.3.3 monolithic codebase into viscy-models with idiomatic pytest test coverage.

Purpose: Complete the legacy UNet migration (UNET-03, UNET-04, UNET-08), making all UNet-family models available from `viscy_models.unet`. These are the last model architectures before the final Phase 10 public API integration.

Output: Two model files (unet2d.py, unet25d.py), updated unet/__init__.py exports, and two test files covering forward pass, state dict keys, and configuration variants.
</objective>

<execution_context>
@/Users/eduardo.hirata/.claude/get-shit-done/workflows/execute-plan.md
@/Users/eduardo.hirata/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-legacy-unet-models/09-RESEARCH.md
@.planning/phases/06-package-scaffold-shared-components/06-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Migrate Unet2d and Unet25d model files to viscy-models</name>
  <files>
    packages/viscy-models/src/viscy_models/unet/unet2d.py
    packages/viscy-models/src/viscy_models/unet/unet25d.py
    packages/viscy-models/src/viscy_models/unet/__init__.py
  </files>
  <action>
    Copy Unet2d from `git show v0.3.3:viscy/unet/networks/Unet2D.py` into `unet2d.py` and Unet25d from `git show v0.3.3:viscy/unet/networks/Unet25D.py` into `unet25d.py`. Apply exactly these changes and NO others:

    1. **Import path update** (both files):
       - Unet2d: `from viscy.unet.networks.layers.ConvBlock2D import ConvBlock2D` becomes `from viscy_models.unet._layers.conv_block_2d import ConvBlock2D`
       - Unet25d: `from viscy.unet.networks.layers.ConvBlock3D import ConvBlock3D` becomes `from viscy_models.unet._layers.conv_block_3d import ConvBlock3D`

    2. **Mutable default fix** (both files):
       - `num_filters=[]` becomes `num_filters=()` in `__init__` signature
       - Internal code (`len(num_filters)`, iteration) works identically with tuples -- no other changes needed

    3. **Add module docstring and __all__** (both files):
       - Unet2d: `"""2D UNet with variable depth and configurable convolutional blocks."""` and `__all__ = ["Unet2d"]`
       - Unet25d: `"""2.5D UNet that learns 3D-to-2D compression for virtual staining."""` and `__all__ = ["Unet25d"]`

    4. **Docstring formatting for ruff D-series** (both files):
       - Fix D400 (first line should end with period), D205 (blank line after summary), D401 (imperative mood) as needed
       - NO logic changes, NO variable renames, NO refactoring

    5. **Preserve verbatim** (critical for checkpoint compatibility):
       - The `register_modules()` method and all `add_module()` calls
       - State dict key patterns: `down_conv_block_N`, `up_conv_block_N`, `down_samp_N`, `skip_conv_layer_N`, `bottom_transition_block`, `terminal_block`
       - The `up_list` as a plain Python list (NOT nn.ModuleList) -- nn.Upsample has no parameters
       - The `squeeze(2)/unsqueeze(2)` in Unet2d.forward
       - The `__name__` method on both classes
       - The `validate_input` parameter in Unet2d.forward

    6. **Update unet/__init__.py** to export all 4 models:
       ```python
       from viscy_models.unet.fcmae import FullyConvolutionalMAE
       from viscy_models.unet.unet2d import Unet2d
       from viscy_models.unet.unet25d import Unet25d
       from viscy_models.unet.unext2 import UNeXt2

       __all__ = ["UNeXt2", "FullyConvolutionalMAE", "Unet2d", "Unet25d"]
       ```

    Remove any `from __future__ import annotations` or other Python 2 compatibility imports from the original source.
  </action>
  <verify>
    Run `python -c "from viscy_models.unet import Unet2d, Unet25d; print('OK')"` to verify imports work.
    Run `uv run --package viscy-models ruff check packages/viscy-models/src/viscy_models/unet/unet2d.py packages/viscy-models/src/viscy_models/unet/unet25d.py` to confirm no lint errors.
    Run `uv run --package viscy-models pytest packages/viscy-models/tests/ --tb=short -q` to confirm existing 46 tests still pass (no regressions).
  </verify>
  <done>
    Unet2d and Unet25d are importable from `viscy_models.unet`. Both files pass ruff linting. All 46 existing tests still pass. No logic changes from v0.3.3 except import paths, mutable defaults, and docstring formatting.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write pytest tests for Unet2d and Unet25d</name>
  <files>
    packages/viscy-models/tests/test_unet/test_unet2d.py
    packages/viscy-models/tests/test_unet/test_unet25d.py
  </files>
  <action>
    Write idiomatic pytest tests for both models. Do NOT port the original unittest tests -- they have combinatorial explosion (144 configs x 3 tests = 432 per model) and depend on `viscy.utils.cli_utils.show_progress_bar` which does not exist in viscy-models. The original test expected shapes are also wrong (pre-date the squeeze/unsqueeze fix in commit 0e2b575).

    **test_unet2d.py** -- approximately 8-10 test cases:

    1. `test_unet2d_default_forward`: Default config (in=1, out=1, num_blocks=4), 5D input `(1, 1, 1, 256, 256)`, verify output shape `(1, 1, 1, 256, 256)`. This exercises the squeeze(2)/unsqueeze(2) path.

    2. `test_unet2d_variable_depth`: `@pytest.mark.parametrize("num_blocks", [1, 2, 4])`. Input `(1, 1, 1, 64, 64)`, verify output shape `(1, 1, 1, 64, 64)`.

    3. `test_unet2d_multichannel`: `in_channels=2, out_channels=3`, verify output channel dimension is 3.

    4. `test_unet2d_residual`: `@pytest.mark.parametrize("residual", [True, False])`. Verify both modes produce same output shape. Optionally verify parameter count is identical (residual mode in ConvBlock2D uses addition, not extra params).

    5. `test_unet2d_task_mode`: `@pytest.mark.parametrize("task", ["reg", "seg"])`. Verify both modes produce valid output shapes. (reg uses linear activation, seg uses relu in terminal block.)

    6. `test_unet2d_dropout`: `dropout=0.25`. Verify forward pass succeeds (dropout active during training, no state dict impact for ConvBlock2D).

    7. `test_unet2d_state_dict_keys`: `num_blocks=2`. Verify state dict key prefixes: `down_conv_block_0`, `down_conv_block_1`, `bottom_transition_block`, `up_conv_block_0`, `up_conv_block_1`, `terminal_block`. Verify `down_samp` is NOT in state dict (AvgPool2d has no params).

    8. `test_unet2d_custom_num_filters`: `num_filters=(32, 64, 128)` with `num_blocks=2`. Verify forward pass succeeds with custom filter sizes.

    **test_unet25d.py** -- approximately 8-10 test cases:

    1. `test_unet25d_default_forward`: `in_stack_depth=5, out_stack_depth=1`, input `(1, 1, 5, 64, 64)`, verify output `(1, 1, 1, 64, 64)`. This is the standard Z-compression case.

    2. `test_unet25d_preserved_depth`: `in_stack_depth=5, out_stack_depth=5`, verify output Z matches input Z. This tests the `kernel_size=(1, 1, 1)` skip path.

    3. `test_unet25d_variable_depth`: `@pytest.mark.parametrize("num_blocks", [1, 2, 4])`. Verify different encoder/decoder depths work.

    4. `test_unet25d_multichannel`: `in_channels=2, out_channels=3`, verify output channel dimension.

    5. `test_unet25d_residual`: `@pytest.mark.parametrize("residual", [True, False])`. Verify both modes produce valid output shapes.

    6. `test_unet25d_task_mode`: `@pytest.mark.parametrize("task", ["reg", "seg"])`. Verify both task modes.

    7. `test_unet25d_state_dict_keys`: `num_blocks=2`. Verify: `down_conv_block_0`, `down_conv_block_1`, `bottom_transition_block`, `up_conv_block_0`, `up_conv_block_1`, `terminal_block`, `skip_conv_layer_0`, `skip_conv_layer_1`. Verify `down_samp` NOT in state dict.

    8. `test_unet25d_custom_num_filters`: `num_filters=(32, 64, 128)` with `num_blocks=2`. Verify forward pass with custom filters.

    All tests use `torch.no_grad()` for forward passes. Use the `device` fixture from conftest.py if available, otherwise CPU-only is fine (these are pure conv models, no GPU-specific behavior).

    Use small spatial dimensions (64x64) and `num_blocks <= 2` for speed in parametrized tests. Only use 256x256 for the single default forward test (num_blocks=4 needs enough spatial resolution for 4 pooling stages).
  </action>
  <verify>
    Run `uv run --package viscy-models pytest packages/viscy-models/tests/test_unet/test_unet2d.py packages/viscy-models/tests/test_unet/test_unet25d.py -v --tb=short` to verify all new tests pass.
    Run `uv run --package viscy-models pytest packages/viscy-models/tests/ --tb=short -q` to verify full suite (existing 46 + new tests) passes with no regressions.
    Run `uv run --package viscy-models ruff check packages/viscy-models/tests/test_unet/test_unet2d.py packages/viscy-models/tests/test_unet/test_unet25d.py` to confirm no lint errors.
  </verify>
  <done>
    All new Unet2d tests pass covering: default forward, variable depth, multichannel, residual, task mode, dropout, state dict keys, and custom filters. All new Unet25d tests pass covering: default forward with Z-compression, preserved depth, variable depth, multichannel, residual, task mode, state dict keys with skip_conv_layer verification, and custom filters. Full test suite passes with no regressions. Total test count increases from 46 to approximately 62-66.
  </done>
</task>

</tasks>

<verification>
After both tasks complete:

1. **Import verification**: `from viscy_models.unet import Unet2d, Unet25d` succeeds
2. **Forward pass**: Both models produce correct output shapes for representative inputs
3. **State dict compatibility**: Key patterns match v0.3.3 checkpoint format exactly
4. **No regressions**: All 46 existing tests still pass
5. **Lint clean**: All new files pass `ruff check`
6. **Requirements satisfied**:
   - UNET-03: Unet2d migrated to unet/unet2d.py (snake_case)
   - UNET-04: Unet25d migrated to unet/unet25d.py (snake_case)
   - UNET-08: Tests migrated from unittest to pytest with parametrize
</verification>

<success_criteria>
- `from viscy_models.unet import Unet2d, Unet25d` works
- Unet2d forward: input (1,1,1,256,256) produces output (1,1,1,256,256)
- Unet25d forward: input (1,1,5,64,64) with out_stack_depth=1 produces output (1,1,1,64,64)
- State dict keys include `down_conv_block_0`, `up_conv_block_0`, `terminal_block` (both models)
- State dict keys include `skip_conv_layer_0` (Unet25d only, NOT Unet2d)
- Full test suite: 60+ tests pass, 0 failures, 1 xfail (pre-existing deconv bug)
- All files pass ruff linting
</success_criteria>

<output>
After completion, create `.planning/phases/09-legacy-unet-models/09-01-SUMMARY.md`
</output>
