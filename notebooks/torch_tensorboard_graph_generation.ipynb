{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbdd1c6a-3737-42f5-8d83-66ab54393576",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d17055-2097-4075-95ea-b18670c69760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6fab4c-4e3f-4609-9d41-0528853fc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c16adb8-5b82-492e-ab9e-6411642fb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9de6afd7-45ff-4b9a-9ff5-5526d16eff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System path: /home/christian.foley/virtual_staining/microDL\n"
     ]
    }
   ],
   "source": [
    "# Add module path to sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "print(\"System path: \"+module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import micro_dl.torch_unet.networks.Unet2D as Unet2D\n",
    "import micro_dl.torch_unet.networks.Unet25D as Unet25D\n",
    "import micro_dl.torch_unet.networks.layers.ConvBlock2D as ConvBlock2D\n",
    "import micro_dl.torch_unet.networks.layers.ConvBlock3D as ConvBlock3D\n",
    "import micro_dl.torch_unet.utils.dataset as ds\n",
    "import micro_dl.torch_unet.utils.io as io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a519954-0ac0-41fe-bb62-6964219ae005",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0173b9d-83e0-4318-a493-e81c7abae1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/hpc/projects/compmicro/projects/virtualstaining/MBL_DL_image_translation/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a84f9c21-9ef0-4d18-9e7d-fdecc2e730ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "train_samples = {}\n",
    "test_samples = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b052944c-8840-46ef-9033-6d04e29d2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in io.unique_tags(data_directory):\n",
    "    measurements = glob.glob(data_directory + '*' + key)\n",
    "    measurements.sort()\n",
    "    num = np.random.uniform(0,1)\n",
    "    if num < 0.9:\n",
    "        train_samples[key] = measurements\n",
    "    else:\n",
    "        test_samples[key] = measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39eccfd4-d988-46b5-a1d7-b1f9e7317b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 22\n"
     ]
    }
   ],
   "source": [
    "print(len(train_samples), len(test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75c443-e52c-47b4-8fe4-19aa59287ca6",
   "metadata": {},
   "source": [
    "### TensorBoard Unet2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbe5238d-1a3b-45aa-a8cf-ec72c5d95af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataloaders\n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = ds.MyDataset(train_samples, transform = transforms.Compose([ds.Resize(), ds.Normalize(), ds.RandFlip(), ds.toTensor()]))\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fea71881-18ec-48b9-b19b-7132260efa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model = Unet2D.Unet2d(in_channels = 1, out_channels = 1, residual = True, task = 'recon')\n",
    "#_ = model.model().cuda()\n",
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "110e363c-1e21-40e8-a12e-2133e5c0167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian.foley/.conda/envs/pt_staining/lib/python3.6/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    }
   ],
   "source": [
    "#test model functionality\n",
    "out = model(next(iter(train_dataloader))['image'])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f46bc1-6234-421c-ba83-e47418b75929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at /hpc/projects/compmicro/projects/virtualstaining/torch_microDL_models/Unet2d/tensorboard_Unet2d_2022_08_30_17_24\n"
     ]
    }
   ],
   "source": [
    "#make graph\n",
    "now = str(datetime.datetime.now()).replace(' ', '_').replace(':','_').replace('-','_')[:-10]\n",
    "save_folder = f'/hpc/projects/compmicro/projects/virtualstaining/torch_microDL_models/Unet2d/tensorboard_{model.__name__()}_{now}'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "writer = SummaryWriter(log_dir = save_folder)\n",
    "nxt = next(iter(train_dataloader))\n",
    "images, labels = nxt['image'], nxt['target']\n",
    "\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('images', grid, 0)\n",
    "writer.add_graph(model, images)\n",
    "print(f'saved at {save_folder}')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb0e26b-27b9-41d2-8323-beb6b6cb87f1",
   "metadata": {},
   "source": [
    "### TensorBoard Unet2.5D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "155bf2c8-4593-4c03-9d7f-2d6a04861f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataloaders\n",
    "batch_size = 5\n",
    "\n",
    "train_dataset = ds.MyDataset(train_samples, transform = transforms.Compose([ds.Resize(), ds.Normalize(), ds.RandFlip(), ds.toTensor()]))\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7f415d0-e68a-4feb-9f1f-a9987323af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model_2 = Unet25D.Unet25d(in_channels = 1, out_channels = 1, in_stack_depth = 5, out_stack_depth = 1, residual = True, task = 'reg')\n",
    "\n",
    "#_ = model.model().cuda()\n",
    "_ = model_2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "98f935a9-af90-41f6-aa5b-34792402714f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5, 256, 256])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = next(iter(train_dataloader))['image']\n",
    "images = torch.transpose(input_, 0, 1).unsqueeze(0)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60ecd746-13f1-4db3-9575-84614bb5bf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "#test model functionality\n",
    "out = model_2(images)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4418db80-c237-4113-acaa-dd6a3da3a964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at /hpc/projects/compmicro/projects/virtualstaining/torch_microDL_models/Unet25d/tensorboard_Unet25d_2022_08_30_19_39\n"
     ]
    }
   ],
   "source": [
    "#make graph\n",
    "now = str(datetime.datetime.now()).replace(' ', '_').replace(':','_').replace('-','_')[:-10]\n",
    "save_folder = f'/hpc/projects/compmicro/projects/virtualstaining/torch_microDL_models/Unet25d/tensorboard_{model_2.__name__()}_{now}'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "writer = SummaryWriter(log_dir = save_folder)\n",
    "\n",
    "# grid = torchvision.utils.make_grid(images)\n",
    "# writer.add_image('images', grid, 0)\n",
    "writer.add_graph(model_2, images)\n",
    "print(f'saved at {save_folder}')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cd05a-ae94-4b78-a105-afc91dd991e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pt_staining]",
   "language": "python",
   "name": "conda-env-.conda-pt_staining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
