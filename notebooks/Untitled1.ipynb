{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4098a68f-6df1-439b-af49-b79a535bd228",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0296ceb-40f0-4bb1-9de9-1119e1b41ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tqdm as notebook_tqdm\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import PIL\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba903720-b003-475d-8660-c34766b0843f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian.foley/.conda/envs/pt_tf_cross/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9d62cd-dbd0-4f7b-be73-3a24fc280561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748c64b8-e139-4226-b542-aab290863875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System path: /home/christian.foley/virtual_staining/microDL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Add module path to sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(\"System path: \"+module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import micro_dl.torch_unet.networks.Unet2D as Unet2D\n",
    "import micro_dl.torch_unet.networks.Unet25D as Unet25D\n",
    "import micro_dl.torch_unet.networks.layers.ConvBlock2D as ConvBlock2D\n",
    "import micro_dl.torch_unet.networks.layers.ConvBlock3D as ConvBlock3D\n",
    "import micro_dl.torch_unet.utils.dataset as ds\n",
    "import micro_dl.torch_unet.utils.io as io\n",
    "import micro_dl.torch_unet.utils.training as training \n",
    "import micro_dl.torch_unet.utils.inference as inference\n",
    "\n",
    "import micro_dl.cli.preprocess_script as preprocess\n",
    "\n",
    "import micro_dl.utils.aux_utils as aux_utils\n",
    "import micro_dl.utils.train_utils as train_utils\n",
    "import micro_dl.utils.preprocess_utils as preprocess_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91921964-aa05-4302-9506-adc474bbc55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config_file_path = '../micro_dl/config_train_25D_torch.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05212a70-386a-44bc-97f9-ca5f590a9913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "173 20 25\n"
     ]
    }
   ],
   "source": [
    "torch_data_container = ds.TorchDataset(train_config_file_path, \n",
    "                                       transforms = [ds.ToTensor()],\n",
    "                                       target_transforms = [ds.ToTensor(), \n",
    "                                                            ds.GenerateMasks(masking_type = 'rosin', clipping = True, clip_amount = (10,0))]) #good practice to put GenerateMasks last in the list of sequential transforms\n",
    "print(len(torch_data_container))\n",
    "\n",
    "train_dataset = torch_data_container['train']\n",
    "test_dataset = torch_data_container['test']\n",
    "val_dataset = torch_data_container['val']\n",
    "print(len(train_dataset), len(test_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a35a9a7-4815-4ac9-b224-f3be190997bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = torch.utils.data.DataLoader(dataset = val_dataset, batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c22440-4910-4ee6-9778-a4eb5a1d8fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function micro_dl.torch_unet.utils.training.run_test(test_dataloader, model, criterion, mask=True, plot=True, plot_num=2, epoch=None, save_folder=None, writer=None, device=device(type='cuda'))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.) TESTING CYCLE\n",
    "testing_cycle = training.run_test\n",
    "testing_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfc4b793-5c65-43a2-b4eb-2d1fe2acc280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.) MODEL/OPT DEFINITION\n",
    "\n",
    "#hyperparameters\n",
    "params = {\n",
    "    'model': {\n",
    "        'architecture': '2.5D',\n",
    "        'in_channels': 1,\n",
    "        'out_channels': 1,\n",
    "        'residual': True,\n",
    "        'task': 'reg', #regression\n",
    "        'device': torch.device('cuda'),\n",
    "        'conv_mode': 'valid'\n",
    "    },\n",
    "    'training': {\n",
    "        'epochs': 100,\n",
    "        'learning_rate': 0.0003,\n",
    "        'optimizer': 'adam',\n",
    "        'loss': nn.MSELoss,\n",
    "        'optimizer': optim.Adam,\n",
    "        'testing_stride': 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "694bb28c-4205-42a6-a46c-d5e7637ad5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Unet25D.Unet25d(in_channels = params['model']['in_channels'], out_channels = params['model']['out_channels'], \n",
    "                        residual = params['model']['residual'], task = params['model']['task'], conv_mode = params['model']['conv_mode'])\n",
    "silent = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07ad2f07-bfc5-4da9-b6a3-2a67ce6fd8b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define loss criterion and optimizer\n",
    "criterion = params['training']['loss']()\n",
    "optimizer = params['training']['optimizer'](model.parameters(), lr = params['training']['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3675b24f-beb8-47cc-9a4d-ae4c50bf7a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 0 shape: torch.Size([16, 1, 5, 256, 256])____________________] (4%)\n",
      "output 0 shape: torch.Size([16, 16, 5, 254, 254])\n",
      "input 1 shape: torch.Size([16, 16, 5, 254, 254])\n",
      "output 1 shape: torch.Size([16, 16, 5, 252, 252])\n",
      "input 2 shape: torch.Size([16, 16, 5, 252, 252])\n",
      "output 2 shape: torch.Size([16, 16, 5, 250, 250])\n",
      "torch.Size([16, 16, 5, 125, 125])\n",
      "input 0 shape: torch.Size([16, 16, 5, 125, 125])\n",
      "output 0 shape: torch.Size([16, 32, 5, 123, 123])\n",
      "input 1 shape: torch.Size([16, 32, 5, 123, 123])\n",
      "output 1 shape: torch.Size([16, 32, 5, 121, 121])\n",
      "input 2 shape: torch.Size([16, 32, 5, 121, 121])\n",
      "output 2 shape: torch.Size([16, 32, 5, 119, 119])\n",
      "torch.Size([16, 32, 5, 59, 59])\n",
      "input 0 shape: torch.Size([16, 32, 5, 59, 59])\n",
      "output 0 shape: torch.Size([16, 64, 5, 57, 57])\n",
      "input 1 shape: torch.Size([16, 64, 5, 57, 57])\n",
      "output 1 shape: torch.Size([16, 64, 5, 55, 55])\n",
      "input 2 shape: torch.Size([16, 64, 5, 55, 55])\n",
      "output 2 shape: torch.Size([16, 64, 5, 53, 53])\n",
      "torch.Size([16, 64, 5, 26, 26])\n",
      "input 0 shape: torch.Size([16, 64, 5, 26, 26])\n",
      "output 0 shape: torch.Size([16, 128, 5, 24, 24])\n",
      "input 1 shape: torch.Size([16, 128, 5, 24, 24])\n",
      "output 1 shape: torch.Size([16, 128, 5, 22, 22])\n",
      "input 2 shape: torch.Size([16, 128, 5, 22, 22])\n",
      "output 2 shape: torch.Size([16, 128, 5, 20, 20])\n",
      "torch.Size([16, 128, 5, 10, 10])\n",
      "torch.Size([16, 256, 1, 10, 10])\n",
      "[torch.Size([16, 16, 1, 250, 250]), torch.Size([16, 32, 1, 119, 119]), torch.Size([16, 64, 1, 53, 53]), torch.Size([16, 128, 1, 20, 20])]\n",
      "torch.Size([16, 256, 1, 10, 10])\n",
      "torch.Size([16, 256, 1, 20, 20])\n",
      "input 0 shape: torch.Size([16, 384, 1, 20, 20])\n",
      "output 0 shape: torch.Size([16, 128, 1, 18, 18])\n",
      "input 1 shape: torch.Size([16, 128, 1, 18, 18])\n",
      "output 1 shape: torch.Size([16, 128, 1, 16, 16])\n",
      "input 2 shape: torch.Size([16, 128, 1, 16, 16])\n",
      "output 2 shape: torch.Size([16, 128, 1, 14, 14])\n",
      "torch.Size([16, 128, 1, 14, 14])\n",
      "torch.Size([16, 128, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 28 but got size 53 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-9f46dfcf07a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesting_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/virtual_staining/microDL/micro_dl/torch_unet/utils/training.py\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m(test_dataloader, model, criterion, mask, plot, plot_num, epoch, save_folder, writer, device)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m#run through model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pt_tf_cross/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtual_staining/microDL/micro_dl/torch_unet/networks/Unet25D.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_conv_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 28 but got size 53 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "testing_cycle(val_dataloader, model, criterion, plot = True, plot_num = 6, mask = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0ff490a-1786-4b76-8747-de52adf1fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand(1,1, 5,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ffa6683-05c7-4cb5-8ef1-14c3cedfd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = (1,3,3)\n",
    "con1 = nn.Conv3d(1, 1, kernel_size = ks, padding = (ks[0]//2, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbade8e0-0568-499e-9d27-8815a9d3c392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5, 250, 250])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_out = con1(con1(con1(z)))\n",
    "z_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b1f20-9b49-4d3a-9f66-8aaf3532bc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pt_tf_cross]",
   "language": "python",
   "name": "conda-env-.conda-pt_tf_cross-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
